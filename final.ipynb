{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.dataloader import DataLoader as myDataLoader\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "# from ast import literal_eval\n",
        "import ast\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Params settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA not available, using CPU\n"
          ]
        }
      ],
      "source": [
        "class Settings():\n",
        "    batch_size = 64\n",
        "    epochs = 20\n",
        "\n",
        "    embedding_size = 64\n",
        "    learning_rate = 0.003\n",
        "    \n",
        "    # 100k dataset - active user\n",
        "    num_users = 943\n",
        "    num_items = 1682\n",
        "    # num_users = 471\n",
        "    # num_items = 841\n",
        "\n",
        "    # Transformer encoder\n",
        "    dropout_rate = 0\n",
        "    num_heads = 4\n",
        "    d_ff = 4\n",
        "    num_blocks = 2\n",
        "\n",
        "\n",
        "    negative_num = 99\n",
        "    # checkpoint_path_user_task = './Checkpoint/user_task/'\n",
        "    # checkpoint_path_item_task = './Checkpoint/item_task/'\n",
        "    verbose = 1\n",
        "\n",
        "    hidden_dim = 256\n",
        "    user_epoch = 5\n",
        "    item_epoch = 25\n",
        "\n",
        "    second_user_epoch = 10\n",
        "    second_item_epoch = 10\n",
        "\n",
        "    third_user_epoch = 10\n",
        "    third_item_epoch = 10\n",
        "\n",
        "    train_user_dataset = './models/gnn_embedding/ml_gnn_ebd/gnn_initial_user_input.csv'\n",
        "    train_item_dataset = './models/gnn_embedding/ml_gnn_ebd/gnn_initial_item_input.csv'\n",
        "    valid_user_dataset = './models/gnn_embedding/ml_gnn_ebd/gnn_target_user_input.csv'\n",
        "    valid_item_dataset = './models/gnn_embedding/ml_gnn_ebd/gnn_target_item_input.csv'\n",
        "\n",
        "    dataset_size = '100k'\n",
        "\n",
        "    # set device\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"Using CUDA (Nvidia GPU)\")\n",
        "        device = torch.device('cuda')\n",
        "    else:\n",
        "        print(\"CUDA not available, using CPU\")\n",
        "        device = torch.device('cpu')\n",
        "\n",
        "\n",
        "settings = Settings()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data loading and searching for 1st 2nd 3rd order neighbours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load the target USER embedding\n",
        "# ['userid', 'embedding']\n",
        "initial_user_embedding_path = \"./models/gnn_embedding/ml_gnn_ebd/initial_user_ebds.csv\"\n",
        "initial_item_embedding_path = \"./models/gnn_embedding/ml_gnn_ebd/initial_item_ebds.csv\"\n",
        "target_user_embedding_path = \"./models/gnn_embedding/ml_gnn_ebd/target_user_ebds.csv\"\n",
        "target_item_embedding_path = \"./models/gnn_embedding/ml_gnn_ebd/target_item_ebds.csv\"\n",
        "\n",
        "initial_user_embedding_df = pd.read_csv(initial_user_embedding_path)\n",
        "initial_item_embedding_df = pd.read_csv(initial_item_embedding_path)  \n",
        "target_user_embedding_df = pd.read_csv(target_user_embedding_path)\n",
        "target_item_embedding_df = pd.read_csv(target_item_embedding_path)\n",
        "\n",
        "# initial_user_embedding_df['embedding'] = initial_user_embedding_df['embedding'].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\",\"))\n",
        "# initial_item_embedding_df['embedding'] = initial_item_embedding_df['embedding'].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\",\"))\n",
        "# target_user_embedding_df['embedding'] = target_user_embedding_df['embedding'].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\",\"))\n",
        "# target_item_embedding_df['embedding'] = target_item_embedding_df['embedding'].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\",\"))\n",
        "\n",
        "# load the rating \n",
        "# ['userId', 'movieId', 'rating', 'timestamp']\n",
        "ratings_df = pd.read_csv(\"./data/ml-100k/u.data\", sep=\"\\t\",header=None, names=[\"user\", \"item\", \"rating\", \"timestamp\"])\n",
        "filtered_user_ids = target_user_embedding_df['user'].unique()\n",
        "filtered_item_ids = target_item_embedding_df['item'].unique()\n",
        "\n",
        "filtered_ratings_df = ratings_df[(ratings_df['user'].isin(filtered_user_ids))&(ratings_df['item'].isin(filtered_item_ids))]\n",
        "filtered_ratings_user_df = filtered_ratings_df[filtered_ratings_df['user'].isin(filtered_user_ids)]\n",
        "filtered_ratings_item_df = filtered_ratings_df[filtered_ratings_df['item'].isin(filtered_item_ids)]\n",
        "\n",
        "\n",
        "filtered_ratings_user_df = ratings_df[ratings_df['user'].isin(filtered_user_ids)]\n",
        "filtered_ratings_item_df = ratings_df[ratings_df['item'].isin(filtered_item_ids)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nodes in user_graph: 1676\n",
            "Edges in user_graph: 79720\n",
            "Nodes in item_graph: 1043\n",
            "Edges in item_graph: 87958\n"
          ]
        }
      ],
      "source": [
        "user_graph = nx.Graph()\n",
        "user_graph.add_nodes_from(filtered_user_ids, bipartite=\"user\")\n",
        "user_graph.add_nodes_from(filtered_ratings_user_df['item'].unique(), bipartite=\"item\")\n",
        "user_graph.add_edges_from(zip(filtered_ratings_user_df['user'], filtered_ratings_user_df['item']))\n",
        "\n",
        "item_graph = nx.Graph()\n",
        "item_graph.add_nodes_from(filtered_item_ids, bipartite=\"item\")\n",
        "item_graph.add_nodes_from(filtered_ratings_item_df['user'].unique(), bipartite=\"user\")\n",
        "item_graph.add_edges_from(zip(filtered_ratings_item_df['item'], filtered_ratings_item_df['user']))\n",
        "\n",
        "\n",
        "print(\"Nodes in user_graph:\", len(user_graph.nodes()))\n",
        "print(\"Edges in user_graph:\", len(user_graph.edges()))\n",
        "print(\"Nodes in item_graph:\", len(item_graph.nodes()))\n",
        "print(\"Edges in item_graph:\", len(item_graph.edges()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pad_or_truncate(lst, target_length, pad_value=0):\n",
        "    lst = lst[:target_length] # truncate\n",
        "    lst += [pad_value] * (target_length - len(lst))  # padding\n",
        "    return lst\n",
        "\n",
        "def get_order_neighbors(graph, node, max_order=3):\n",
        "\n",
        "    neighbors = {1: set(graph.neighbors(node))}\n",
        "    for order in range(2, max_order + 1):\n",
        "        neighbors[order] = set()\n",
        "        for neighbor in neighbors[order - 1]:\n",
        "            neighbors[order].update(graph.neighbors(neighbor))\n",
        "        # TODO\n",
        "        for prev_order in range(1, order):\n",
        "            neighbors[order] -= neighbors[prev_order]\n",
        "    return [list(neighbors[i]) for i in range(1, max_order + 1)]\n",
        "\n",
        "def compute_max_neighbors(graph, ids, max_order=3):\n",
        "    max_neighbors = {order: 0 for order in range(1, max_order + 1)}\n",
        "    for node in ids:\n",
        "        neighbors = get_order_neighbors(graph, node, max_order=max_order)\n",
        "        for order in range(1, max_order + 1):\n",
        "            current_length = len(neighbors[order - 1])\n",
        "            if current_length > max_neighbors[order]:\n",
        "                max_neighbors[order] = current_length\n",
        "    return max_neighbors\n",
        "\n",
        "def compute_neighbors_with_padding(graph, ids, embeddings_df, max_neighbors, max_order=3, pad_value=0):\n",
        "    data = []\n",
        "    for node_id in ids:\n",
        "        neighbors = get_order_neighbors(graph, node_id, max_order=max_order)\n",
        "        padded_neighbors = [\n",
        "            pad_or_truncate(list(neighbors[order - 1]), max_neighbors, pad_value=pad_value)\n",
        "            for order in range(1, max_order + 1)\n",
        "        ]\n",
        "        if 'user' in embeddings_df.columns:\n",
        "            embedding = embeddings_df.loc[embeddings_df['user'] == node_id, 'embedding'].values[0]\n",
        "        else:\n",
        "            embedding = embeddings_df.loc[embeddings_df['item'] == node_id, 'embedding'].values[0]\n",
        "        data.append({\n",
        "            'id': node_id,\n",
        "            '1st_order': padded_neighbors[0],\n",
        "            '2nd_order': padded_neighbors[1],\n",
        "            '3rd_order': padded_neighbors[2],\n",
        "            'oracle_embedding': embedding\n",
        "        })\n",
        "    return pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "'int' object is not subscriptable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[44], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m max_user_neighbors \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mnum_users\n\u001b[1;32m     11\u001b[0m max_item_neighbors \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mnum_items\n\u001b[0;32m---> 13\u001b[0m initial_user_input_df \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_neighbors_with_padding\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiltered_user_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_user_embedding_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_user_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m initial_item_input_df \u001b[38;5;241m=\u001b[39m compute_neighbors_with_padding(item_graph, filtered_item_ids, initial_item_embedding_df, max_item_neighbors, max_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     15\u001b[0m target_user_input_df \u001b[38;5;241m=\u001b[39m compute_neighbors_with_padding(user_graph, filtered_user_ids, target_user_embedding_df, max_user_neighbors, max_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
            "Cell \u001b[0;32mIn[43], line 32\u001b[0m, in \u001b[0;36mcompute_neighbors_with_padding\u001b[0;34m(graph, ids, embeddings_df, max_neighbors, max_order, pad_value)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node_id \u001b[38;5;129;01min\u001b[39;00m ids:\n\u001b[1;32m     31\u001b[0m     neighbors \u001b[38;5;241m=\u001b[39m get_order_neighbors(graph, node_id, max_order\u001b[38;5;241m=\u001b[39mmax_order)\n\u001b[0;32m---> 32\u001b[0m     padded_neighbors \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     33\u001b[0m         pad_or_truncate(\u001b[38;5;28mlist\u001b[39m(neighbors[order \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]), max_neighbors[order], pad_value\u001b[38;5;241m=\u001b[39mpad_value)\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m order \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, max_order \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     35\u001b[0m     ]\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m embeddings_df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m     37\u001b[0m         embedding \u001b[38;5;241m=\u001b[39m embeddings_df\u001b[38;5;241m.\u001b[39mloc[embeddings_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m node_id, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n",
            "Cell \u001b[0;32mIn[43], line 33\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node_id \u001b[38;5;129;01min\u001b[39;00m ids:\n\u001b[1;32m     31\u001b[0m     neighbors \u001b[38;5;241m=\u001b[39m get_order_neighbors(graph, node_id, max_order\u001b[38;5;241m=\u001b[39mmax_order)\n\u001b[1;32m     32\u001b[0m     padded_neighbors \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 33\u001b[0m         pad_or_truncate(\u001b[38;5;28mlist\u001b[39m(neighbors[order \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]), \u001b[43mmax_neighbors\u001b[49m\u001b[43m[\u001b[49m\u001b[43morder\u001b[49m\u001b[43m]\u001b[49m, pad_value\u001b[38;5;241m=\u001b[39mpad_value)\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m order \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, max_order \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     35\u001b[0m     ]\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m embeddings_df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m     37\u001b[0m         embedding \u001b[38;5;241m=\u001b[39m embeddings_df\u001b[38;5;241m.\u001b[39mloc[embeddings_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m node_id, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "# max_user_neighbors = compute_max_neighbors(user_graph, filtered_user_ids, max_order=3)\n",
        "# max_item_neighbors = compute_max_neighbors(item_graph, filtered_item_ids, max_order=3)\n",
        "# print(\"Max 1st order neighbors (user):\", max_user_neighbors[1])\n",
        "# print(\"Max 2nd order neighbors (user):\", max_user_neighbors[2])\n",
        "# print(\"Max 3rd order neighbors (user):\", max_user_neighbors[3])\n",
        "\n",
        "# print(\"Max 1st order neighbors (item):\", max_item_neighbors[1])\n",
        "# print(\"Max 2nd order neighbors (item):\", max_item_neighbors[2])\n",
        "# print(\"Max 3rd order neighbors (item):\", max_item_neighbors[3])\n",
        "max_user_neighbors = settings.num_users\n",
        "max_item_neighbors = settings.num_items\n",
        "\n",
        "initial_user_input_df = compute_neighbors_with_padding(user_graph, filtered_user_ids, initial_user_embedding_df, max_user_neighbors, max_order=3)\n",
        "initial_item_input_df = compute_neighbors_with_padding(item_graph, filtered_item_ids, initial_item_embedding_df, max_item_neighbors, max_order=3)\n",
        "target_user_input_df = compute_neighbors_with_padding(user_graph, filtered_user_ids, target_user_embedding_df, max_user_neighbors, max_order=3)\n",
        "target_item_input_df = compute_neighbors_with_padding(item_graph, filtered_item_ids, target_item_embedding_df, max_item_neighbors, max_order=3)\n",
        "\n",
        "# initial_user_input_df.to_csv(\"./models/gnn_embedding/ml_gnn_ebd/gnn_initial_user_input.csv\", index=False)\n",
        "# initial_item_input_df.to_csv(\"./models/gnn_embedding/ml_gnn_ebd/gnn_initial_item_input.csv\", index=False)\n",
        "# target_user_input_df.to_csv(\"./models/gnn_embedding/ml_gnn_ebd/gnn_target_user_input.csv\", index=False)\n",
        "# target_item_input_df.to_csv(\"./models/gnn_embedding/ml_gnn_ebd/gnn_target_item_input.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "def csv_to_dataloader(file_path, batch_size, column_specs, shuffle=True):\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    tensor_list = []\n",
        "    for col, dtype in column_specs.items():\n",
        "        if col == \"id\":\n",
        "            tensor = torch.tensor(df[col].values, dtype=dtype)\n",
        "        elif col in [\"1st_order\", \"2nd_order\", \"3rd_order\"]:\n",
        "            tensor = torch.tensor(df[col].apply(ast.literal_eval).tolist(), dtype=dtype)\n",
        "        elif col == \"oracle_embedding\":\n",
        "            tensor = torch.tensor(df[col].apply(ast.literal_eval).tolist(), dtype=dtype)\n",
        "        else:\n",
        "            raise ValueError(f\"error in column: {col}\")\n",
        "        \n",
        "        tensor_list.append(tensor)\n",
        "\n",
        "    dataset = TensorDataset(*tensor_list)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "initial_user_input_path = \"./models/gnn_embedding/ml_gnn_ebd/gnn_initial_user_input.csv\"\n",
        "initial_item_input_path = \"./models/gnn_embedding/ml_gnn_ebd/gnn_initial_item_input.csv\"\n",
        "target_user_input_path = \"./models/gnn_embedding/ml_gnn_ebd/gnn_target_user_input.csv\"\n",
        "target_item_input_path = \"./models/gnn_embedding/ml_gnn_ebd/gnn_target_item_input.csv\"\n",
        "\n",
        "# train_user_dataset = CSVToDataset(initial_user_input_path, \"userid\")\n",
        "# train_item_dataset = CSVToDataset(initial_item_input_path, \"itemid\")\n",
        "# valid_user_dataset = CSVToDataset(target_user_input_path, \"userid\")\n",
        "# valid_item_dataset = CSVToDataset(target_item_input_path, \"itemid\")\n",
        "\n",
        "# train_user_loader = DataLoader(train_user_dataset, batch_size=settings.batch_size, shuffle=True)\n",
        "# train_item_loader = DataLoader(train_item_dataset, batch_size=settings.batch_size, shuffle=True)\n",
        "# valid_user_loader = DataLoader(valid_user_dataset, batch_size=settings.batch_size, shuffle=False)\n",
        "# valid_item_loader = DataLoader(valid_item_dataset, batch_size=settings.batch_size, shuffle=False)\n",
        "\n",
        "columns_to_tensor_user = {\n",
        "    \"id\": torch.long,\n",
        "    \"1st_order\": torch.long,\n",
        "    \"2nd_order\": torch.long,\n",
        "    \"3rd_order\": torch.long,\n",
        "    \"oracle_embedding\": torch.float32, \n",
        "}\n",
        "\n",
        "columns_to_tensor_item = {\n",
        "    \"id\": torch.long,\n",
        "    \"1st_order\": torch.long,\n",
        "    \"2nd_order\": torch.long,\n",
        "    \"3rd_order\": torch.long,\n",
        "    \"oracle_embedding\": torch.float32,\n",
        "}\n",
        "\n",
        "b_size = settings.batch_size\n",
        "\n",
        "train_user_loader = csv_to_dataloader(initial_user_input_path, b_size, columns_to_tensor_user, shuffle=True)\n",
        "train_item_loader = csv_to_dataloader(initial_item_input_path, b_size, columns_to_tensor_item, shuffle=True)\n",
        "valid_user_loader = csv_to_dataloader(target_user_input_path, b_size, columns_to_tensor_user, shuffle=False)\n",
        "valid_item_loader = csv_to_dataloader(target_item_input_path, b_size, columns_to_tensor_item, shuffle=False)\n",
        "\n",
        "\n",
        "\n",
        "# for batch in train_user_loader:\n",
        "#     user_ids, first_order, second_order, third_order, oracle_embeddings = batch\n",
        "#     print(\"User IDs:\", user_ids)\n",
        "#     print(\"First Order Neighbors:\", first_order)\n",
        "#     print(\"Second Order Neighbors:\", second_order)\n",
        "#     print(\"Third Order Neighbors:\", third_order)\n",
        "#     print(\"Oracle Embeddings:\", oracle_embeddings)\n",
        "#     break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train First Embedding with 1rd, 2nd, 3rd order user item relationship"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "from models.gnn_embedding.GeneralGNN import GeneralGNN\n",
        "from models.gnn_embedding.train_helper import train_first_order_task, train_second_order_task, train_third_order_task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = GeneralGNN(name=\"GraphSAGE\", settings=settings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training user tasks...\n",
            " -> Training 1st order user tasks...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/20 - Training First-Order user Task: 100%|██████████| 8/8 [00:00<00:00, 135.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20 - First-Order user Task: Train Loss = 1.0013\n",
            "IndexError during validation: index out of range in self\n",
            "Support_1st IDs: tensor([[  2,   4,   8,  ...,   0,   0,   0],\n",
            "        [  4,  10, 524,  ...,   0,   0,   0],\n",
            "        [513,   1,   4,  ...,   0,   0,   0],\n",
            "        ...,\n",
            "        [  1,   4,   7,  ...,   0,   0,   0],\n",
            "        [512, 515,   4,  ...,   0,   0,   0],\n",
            "        [512, 513,   1,  ...,   0,   0,   0]])\n",
            "Support_2nd IDs: tensor([[1, 3, 5,  ..., 0, 0, 0],\n",
            "        [1, 2, 3,  ..., 0, 0, 0],\n",
            "        [2, 3, 5,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [2, 3, 5,  ..., 0, 0, 0],\n",
            "        [1, 2, 3,  ..., 0, 0, 0],\n",
            "        [2, 3, 5,  ..., 0, 0, 0]])\n",
            "Support_3rd IDs: tensor([[ 599,  677,  957,  ...,    0,    0,    0],\n",
            "        [ 599,  677,  987,  ...,    0,    0,    0],\n",
            "        [ 814,  850,  852,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [ 352,  695,  935,  ...,    0,    0,    0],\n",
            "        [  74, 1080, 1116,  ...,    0,    0,    0],\n",
            "        [ 599,  677,  957,  ...,    0,    0,    0]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "index out of range in self",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[37], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining user tasks...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m -> Training 1st order user tasks...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mtrain_first_order_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_user_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_user_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m -> Training 2nd order user tasks...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m train_second_order_task(\n\u001b[1;32m     18\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     19\u001b[0m     train_loader\u001b[38;5;241m=\u001b[39mtrain_user_loader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     24\u001b[0m )\n",
            "File \u001b[0;32m~/Downloads/cs5284_graphML/project/dinghui101/models/gnn_embedding/train_helper.py:40\u001b[0m, in \u001b[0;36mtrain_first_order_task\u001b[0;34m(model, train_loader, valid_loader, epochs, device, task)\u001b[0m\n\u001b[1;32m     37\u001b[0m avg_train_loss \u001b[38;5;241m=\u001b[39m train_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - First-Order \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Task: Train Loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_train_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 40\u001b[0m \u001b[43mvalidate_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFirst-Order\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Downloads/cs5284_graphML/project/dinghui101/models/gnn_embedding/train_helper.py:134\u001b[0m, in \u001b[0;36mvalidate_task\u001b[0;34m(model, valid_loader, loss_fn, device, task, order)\u001b[0m\n\u001b[1;32m    131\u001b[0m oracle_embeddings \u001b[38;5;241m=\u001b[39m oracle_embeddings\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 134\u001b[0m     predicted_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msupport_1st\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msupport_2nd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msupport_3rd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndexError during validation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/miniconda3/envs/rec_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/rec_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/Downloads/cs5284_graphML/project/dinghui101/models/gnn_embedding/GeneralGNN.py:108\u001b[0m, in \u001b[0;36mGeneralGNN.forward\u001b[0;34m(self, target_ids, support_1st, support_2nd, support_3rd, task, aggregation)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m support_2nd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;66;03m# Second-order neighbors are users for user tasks\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m         second_order_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43msupport_2nd\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Shape: [batch_size, num_neighbors_2nd, embedding_size]\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m task \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitem\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;66;03m# Second-order neighbors are items for item tasks\u001b[39;00m\n\u001b[1;32m    111\u001b[0m         second_order_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_embeddings(support_2nd)  \u001b[38;5;66;03m# Shape: [batch_size, num_neighbors_2nd, embedding_size]\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/rec_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/rec_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/rec_env/lib/python3.9/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/rec_env/lib/python3.9/site-packages/torch/nn/functional.py:2264\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2258\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2259\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2260\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2261\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2262\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2263\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
          ]
        }
      ],
      "source": [
        "# Train for user tasks\n",
        "num_epochs = settings.epochs\n",
        "device = settings.device\n",
        "\n",
        "print(\"Training user tasks...\")\n",
        "print(\" -> Training 1st order user tasks...\")\n",
        "train_first_order_task(\n",
        "    model=model,\n",
        "    train_loader=train_user_loader,\n",
        "    valid_loader=valid_user_loader,\n",
        "    epochs=num_epochs,\n",
        "    device=device,\n",
        "    task=\"user\",\n",
        ")\n",
        "\n",
        "print(\" -> Training 2nd order user tasks...\")\n",
        "train_second_order_task(\n",
        "    model=model,\n",
        "    train_loader=train_user_loader,\n",
        "    valid_loader=valid_user_loader,\n",
        "    epochs=num_epochs,\n",
        "    device=device,\n",
        "    task=\"user\",\n",
        ")\n",
        "\n",
        "print(\" -> Training 3rd order user tasks...\")\n",
        "train_third_order_task(\n",
        "    model=model,\n",
        "    train_loader=train_user_loader,\n",
        "    valid_loader=valid_user_loader,\n",
        "    epochs=num_epochs,\n",
        "    device=device,\n",
        "    task=\"user\",\n",
        ")\n",
        "\n",
        "# Train for item tasks\n",
        "print(\"Training item tasks...\")\n",
        "print(\" -> Training 1st order item tasks...\")\n",
        "train_first_order_task(\n",
        "    model=model,\n",
        "    train_loader=train_item_loader,\n",
        "    valid_loader=valid_item_loader,\n",
        "    epochs=num_epochs,\n",
        "    device=device,\n",
        "    task=\"item\",\n",
        ")\n",
        "\n",
        "print(\" -> Training 2nd order item tasks...\")\n",
        "train_second_order_task(\n",
        "    model=model,\n",
        "    train_loader=train_item_loader,\n",
        "    valid_loader=valid_item_loader,\n",
        "    epochs=num_epochs,\n",
        "    device=device,\n",
        "    task=\"item\",\n",
        ")\n",
        "\n",
        "print(\" -> Training 3rd order item tasks...\")\n",
        "train_third_order_task(\n",
        "    model=model,\n",
        "    train_loader=train_item_loader,\n",
        "    valid_loader=valid_item_loader,\n",
        "    epochs=num_epochs,\n",
        "    device=device,\n",
        "    task=\"item\",\n",
        ")\n",
        "\n",
        "print(\"Training completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Movie Data aggragation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "gnn_course",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
