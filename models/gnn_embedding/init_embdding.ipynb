{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to visualize the generation of the initial embedding and target embedding from lightGCN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root directory to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../..\")))\n",
    "\n",
    "# Import modules from the utils folder\n",
    "from utils.dataloader import DataLoader\n",
    "from utils.data_split import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data = DataLoader(size=\"100k\")\n",
    "data = movie_data.load_ratings()\n",
    "train_set, test_set = train_test_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ratings = train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1609"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_ratings['item'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50% Users DataFrame:\n",
      "(471, 1)\n",
      "\n",
      "Top 50% Items DataFrame:\n",
      "(804, 1)\n"
     ]
    }
   ],
   "source": [
    "# Calculate user degree\n",
    "user_degree_df = training_ratings.groupby(\"user\").size().reset_index(name=\"degree\")\n",
    "\n",
    "# Calculate item degree\n",
    "item_degree_df = training_ratings.groupby(\"item\").size().reset_index(name=\"degree\")\n",
    "\n",
    "# Determine the cutoff for top 50% users and items based on degree\n",
    "user_cutoff = int(len(user_degree_df) * 0.5)\n",
    "item_cutoff = int(len(item_degree_df) * 0.5)\n",
    "\n",
    "# Get top 50% users and items\n",
    "top_users_df = user_degree_df.nlargest(user_cutoff, 'degree')[['user']]\n",
    "top_items_df = item_degree_df.nlargest(item_cutoff, 'degree')[['item']]\n",
    "\n",
    "# Display the DataFrames\n",
    "print(\"Top 50% Users DataFrame:\")\n",
    "print(top_users_df.shape)\n",
    "\n",
    "print(\"\\nTop 50% Items DataFrame:\")\n",
    "print(top_items_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>332</td>\n",
       "      <td>566</td>\n",
       "      <td>4</td>\n",
       "      <td>888360342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>332</td>\n",
       "      <td>451</td>\n",
       "      <td>5</td>\n",
       "      <td>888360179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>332</td>\n",
       "      <td>595</td>\n",
       "      <td>4</td>\n",
       "      <td>887938574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>332</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>888360342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>332</td>\n",
       "      <td>258</td>\n",
       "      <td>5</td>\n",
       "      <td>887916151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65546</th>\n",
       "      <td>436</td>\n",
       "      <td>427</td>\n",
       "      <td>3</td>\n",
       "      <td>887769105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65547</th>\n",
       "      <td>436</td>\n",
       "      <td>234</td>\n",
       "      <td>3</td>\n",
       "      <td>887769471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65548</th>\n",
       "      <td>436</td>\n",
       "      <td>187</td>\n",
       "      <td>5</td>\n",
       "      <td>887768982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65551</th>\n",
       "      <td>436</td>\n",
       "      <td>856</td>\n",
       "      <td>4</td>\n",
       "      <td>887769952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65552</th>\n",
       "      <td>436</td>\n",
       "      <td>468</td>\n",
       "      <td>4</td>\n",
       "      <td>887771826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50548 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user  item  rating  timestamp\n",
       "85      332   566       4  888360342\n",
       "86      332   451       5  888360179\n",
       "87      332   595       4  887938574\n",
       "88      332    44       3  888360342\n",
       "90      332   258       5  887916151\n",
       "...     ...   ...     ...        ...\n",
       "65546   436   427       3  887769105\n",
       "65547   436   234       3  887769471\n",
       "65548   436   187       5  887768982\n",
       "65551   436   856       4  887769952\n",
       "65552   436   468       4  887771826\n",
       "\n",
       "[50548 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_user_movie_rating = training_ratings[\n",
    "    (training_ratings['user'].isin(top_users_df['user'])) &\n",
    "    (training_ratings['item'].isin(top_items_df['item']))\n",
    "]\n",
    "filtered_user_movie_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Embeddings Shape: torch.Size([471, 64])\n",
      "Item Embeddings Shape: torch.Size([804, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../\")))\n",
    "\n",
    "from lightgcn_model import LightGCN, LightGCNModel\n",
    "\n",
    "filtered_user_movie_rating = filtered_user_movie_rating[['user','item','rating']]\n",
    "\n",
    "# Assuming filtered_user_movie_rating is already available\n",
    "# and contains the columns 'user', 'item', and 'rating'.\n",
    "\n",
    "# Split the filtered dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(filtered_user_movie_rating, test_size=0.3, random_state=42)\n",
    "\n",
    "# Instantiate LightGCNModel with the filtered data\n",
    "model = LightGCNModel(\n",
    "    train_set=train_set,\n",
    "    test_set=test_set,\n",
    "    num_layers=3,        \n",
    "    embedding_dim=64,    \n",
    "    learning_rate=0.01,  \n",
    "    epochs=50,          \n",
    "    device='cpu'         \n",
    ")\n",
    "\n",
    "# Prepare training data (includes building graph and initializing model)\n",
    "model.prepare_training_data()\n",
    "\n",
    "\n",
    "with torch.no_grad():  \n",
    "    user_embeddings, item_embeddings = model.model(model.adj_norm)\n",
    "\n",
    "print(\"User Embeddings Shape:\", user_embeddings.shape)  # Shape: (num_users, embedding_dim)\n",
    "print(\"Item Embeddings Shape:\", item_embeddings.shape)  # Shape: (num_items, embedding_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Embeddings DataFrame:\n",
      "(471, 2)\n",
      "\n",
      "Item Embeddings DataFrame:\n",
      "(804, 2)\n"
     ]
    }
   ],
   "source": [
    "# Convert user_embeddings to DataFrame\n",
    "target_user_embeddings = pd.DataFrame({\n",
    "    'user': [model.idx2user[i] for i in range(user_embeddings.shape[0])],  # Map row indices to user IDs\n",
    "    'embedding': user_embeddings.cpu().numpy().tolist()  # Convert tensor rows to lists\n",
    "})\n",
    "\n",
    "# Convert item_embeddings to DataFrame\n",
    "target_item_embeddings = pd.DataFrame({\n",
    "    'item': [model.idx2item[i] for i in range(item_embeddings.shape[0])],  # Map row indices to item IDs\n",
    "    'embedding': item_embeddings.cpu().numpy().tolist()  # Convert tensor rows to lists\n",
    "})\n",
    "\n",
    "# Display the DataFrames\n",
    "print(\"User Embeddings DataFrame:\")\n",
    "print(target_user_embeddings.shape)\n",
    "\n",
    "print(\"\\nItem Embeddings DataFrame:\")\n",
    "print(target_item_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Embeddings DataFrame:\n",
      "(471, 2)\n",
      "Item Embeddings DataFrame:\n",
      "(804, 2)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Step 1: Define the number of users and embedding dimension\n",
    "num_users = len(top_users_df['user'])  # Assuming user_degree_df contains the user IDs\n",
    "num_items = len(top_items_df['item'])\n",
    "embedding_dim = 64  # Specify embedding dimension\n",
    "\n",
    "# Step 2: Initialize the embedding layer\n",
    "init_user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "init_item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "# Step 3: Apply Xavier Uniform Initialization\n",
    "nn.init.xavier_uniform_(init_user_embedding.weight)\n",
    "nn.init.xavier_uniform_(init_item_embedding.weight)\n",
    "\n",
    "# Step 4: Convert initialized embeddings into a DataFrame\n",
    "user_ids = top_users_df['user'].values  # Extract user IDs from top_users_df\n",
    "user_embeddings = init_user_embedding.weight.cpu().detach().numpy()  # Convert to numpy array\n",
    "item_ids = top_items_df['item'].values  # Extract item IDs from top_users_df\n",
    "item_embeddings = init_item_embedding.weight.cpu().detach().numpy()  # Convert to numpy array\n",
    "\n",
    "# Create DataFrame\n",
    "user_embeddings_df = pd.DataFrame({\n",
    "    'user': user_ids,  # Map rows to user IDs\n",
    "    'embedding': user_embeddings.tolist()  # Convert each embedding row to a list\n",
    "})\n",
    "\n",
    "item_embeddings_df = pd.DataFrame({\n",
    "    'item': item_ids,  # Map rows to item IDs\n",
    "    'embedding': item_embeddings.tolist()  # Convert each embedding row to a list\n",
    "})\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(\"User Embeddings DataFrame:\")\n",
    "print(user_embeddings_df.shape)\n",
    "\n",
    "print(\"Item Embeddings DataFrame:\")\n",
    "print(item_embeddings_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "\n",
    "# Define the folder name\n",
    "output_folder = \"ml_gnn_ebd\"\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Save the CSV files into the specified folder\n",
    "user_embeddings_df.to_csv(os.path.join(output_folder, \"initial_user_ebds.csv\"), index=False)\n",
    "item_embeddings_df.to_csv(os.path.join(output_folder, \"initial_item_ebds.csv\"), index=False)\n",
    "target_user_embeddings.to_csv(os.path.join(output_folder, \"target_user_ebds.csv\"), index=False)\n",
    "target_item_embeddings.to_csv(os.path.join(output_folder, \"target_item_ebds.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
