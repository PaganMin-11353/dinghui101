{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark with Movielens dataset\n",
    "The main purpose of this notebook is not to produce comprehensive benchmarking results on multiple datasets. Rather, it is intended to evaluate different recommender algorithms(SVD, LightGCN, Transformer and our algorithm) in this repository.\n",
    "\n",
    "* Datasets\n",
    "  * [Movielens 100K](https://grouplens.org/datasets/movielens/100k/).\n",
    "  * [Movielens 1M](https://grouplens.org/datasets/movielens/1m/).\n",
    "\n",
    "* Data split\n",
    "  * TODO\n",
    "  \n",
    "\n",
    "* Evaluation metrics\n",
    "  * Ranking metrics:\n",
    "    * Precision@k.\n",
    "    * Recall@k.\n",
    "    * Normalized discounted cumulative gain@k (NDCG@k).\n",
    "    * Mean-average-precision (MAP). \n",
    "  * Rating metrics:\n",
    "    * Root mean squared error (RMSE).\n",
    "    * Mean average error (MAE).\n",
    "    * R squared.\n",
    "    * Explained variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/sun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (2.5.0)\n",
      "Requirement already satisfied: filelock in /Users/sun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/sun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: networkx in /Users/sun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from torch) (3.4.1)\n",
      "Requirement already satisfied: jinja2 in /Users/sun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/sun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/sun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/sun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR) \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.dataloader import load_data_df, load_item_df, load_user_features, maybe_download\n",
    "from models.svd_model import SVDModel\n",
    "from utils.benchmark import calculate_rating_metrics, calculate_ranking_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(data, algo, k, rating_metrics, ranking_metrics):\n",
    "    summary = {\"Data\": data, \"Algo\": algo, \"K\": k}\n",
    "    if rating_metrics is None:\n",
    "        rating_metrics = {\n",
    "            \"RMSE\": np.nan,\n",
    "            \"MAE\": np.nan,\n",
    "            \"R2\": np.nan,\n",
    "            \"Explained Variance\": np.nan,\n",
    "        }\n",
    "    if ranking_metrics is None:\n",
    "        ranking_metrics = {\n",
    "            \"MAP\": np.nan,\n",
    "            \"nDCG@k\": np.nan,\n",
    "            \"Precision@k\": np.nan,\n",
    "            \"Recall@k\": np.nan,\n",
    "        }\n",
    "    summary.update(rating_metrics)\n",
    "    summary.update(ranking_metrics)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sun/Desktop/NUS/CS5248/project/movie_recommdender/dinghui101/data/ml-100k/u.data\n",
      "/Users/sun/Desktop/NUS/CS5248/project/movie_recommdender/dinghui101/data/ml-100k/u.data\n"
     ]
    }
   ],
   "source": [
    "cols = [\"Data\", \"Algo\", \"K\", \"RMSE\", \"MAE\", \"R2\", \"Explained Variance\", \"MAP\", \"nDCG@k\", \"Precision@k\", \"Recall@k\"]\n",
    "df_results = pd.DataFrame(columns=cols)\n",
    "size = \"100k\"\n",
    "svd_model = SVDModel(size, n_factors=200, n_epochs=30)\n",
    "data = svd_model.prepare_training_data()\n",
    "svd_model.train()\n",
    "predictions = svd_model.predict()\n",
    "\n",
    "ratings = calculate_rating_metrics(svd_model.test_pre, predictions)\n",
    "\n",
    "top_k_scores = svd_model.recommend_k_svd()\n",
    "rankings = calculate_ranking_metrics(svd_model.test_pre, top_k_scores, 10)\n",
    "\n",
    "summary = generate_summary(\"100k\", \"svd\", 10,  ratings, rankings)\n",
    "df_results.loc[df_results.shape[0] + 1] = summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Algo</th>\n",
       "      <th>K</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>Explained Variance</th>\n",
       "      <th>MAP</th>\n",
       "      <th>nDCG@k</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Recall@k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100k</td>\n",
       "      <td>svd</td>\n",
       "      <td>10</td>\n",
       "      <td>0.950361</td>\n",
       "      <td>0.748291</td>\n",
       "      <td>0.285657</td>\n",
       "      <td>0.285712</td>\n",
       "      <td>0.015655</td>\n",
       "      <td>0.111098</td>\n",
       "      <td>0.100849</td>\n",
       "      <td>0.034672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data Algo   K      RMSE       MAE        R2  Explained Variance       MAP  \\\n",
       "1  100k  svd  10  0.950361  0.748291  0.285657            0.285712  0.015655   \n",
       "\n",
       "     nDCG@k  Precision@k  Recall@k  \n",
       "1  0.111098     0.100849  0.034672  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each data size and each algorithm, a recommender is evaluated. \n",
    "cols = [\"Data\", \"Algo\", \"K\", \"Train time (s)\", \"Predicting time (s)\", \"RMSE\", \"MAE\", \"R2\", \"Explained Variance\", \"Recommending time (s)\", \"MAP\", \"nDCG@k\", \"Precision@k\", \"Recall@k\"]\n",
    "df_results = pd.DataFrame(columns=cols)\n",
    "\n",
    "data_sizes = [\"100k\", \"1m\"]\n",
    "algorithms = [\"svd\",  \"lightgcn\"] #Base line algorithms\n",
    "\n",
    "metrics = {\n",
    "    \"svd\": [\"rating\", \"ranking\"],\n",
    "    \"lightgcn\": [\"ranking\"]\n",
    "}\n",
    "\n",
    "def benchmark_recommenders(data_sizes, algorithms):\n",
    "    global df_results\n",
    "    for data_size in data_sizes:\n",
    "        df = load_data_df(size=data_size)\n",
    "        print(f\"Size of Movielens {data_size}: {df.shape}\")\n",
    "        \n",
    "        # Split Data set\n",
    "        train_data, test_data = train_test_split(df, train_size=0.75, random_state=42, shuffle=True)\n",
    "        print(train_data)\n",
    "        print(test_data)\n",
    "        \n",
    "    #     for algo in algorithms:\n",
    "    #         print(f\"\\nComputing {algo} algorithm on Movielens {data_size}\")\n",
    "            \n",
    "    #         # 准备训练数据\n",
    "    #         train = prepare_training_data.get(algo, lambda x,y:(x,y))(data_train, data_test)\n",
    "            \n",
    "    #         # 获取模型参数并训练\n",
    "    #         model_params = params[algo]\n",
    "    #         model, time_train = trainer[algo](model_params, train)\n",
    "    #         print(f\"Training time: {time_train}s\")\n",
    "            \n",
    "    #         # 评价模型表现\n",
    "    #         ratings, time_rating, rankings, time_ranking = evaluate_model(algo, model, data_test, train)\n",
    "            \n",
    "    #         # 记录结果\n",
    "    #         summary = generate_summary(data_size, algo, DEFAULT_K, time_train, time_rating, ratings, time_ranking, rankings)\n",
    "    #         df_results.loc[df_results.shape[0]] = summary\n",
    "\n",
    "    # return df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file is already exist\n",
      "/Users/sun/Desktop/NUS/CS5248/project/movie_recommdender/dinghui101/data/ml-100k/u.data\n",
      "Size of Movielens 100k: (100000, 4)\n",
      "       UserId  MovieId  Rating  Timestamp\n",
      "98980     811      901       4  886377771\n",
      "69824     804      755       3  879445305\n",
      "9928       52      287       5  882922357\n",
      "75599     735      181       4  876698604\n",
      "95621     897       96       5  879990430\n",
      "...       ...      ...     ...        ...\n",
      "6265      216      231       2  880245109\n",
      "54886     343      276       5  876403078\n",
      "76820     437      475       3  880140288\n",
      "860       284      322       3  885329671\n",
      "15795     222      200       3  878181647\n",
      "\n",
      "[75000 rows x 4 columns]\n",
      "       UserId  MovieId  Rating  Timestamp\n",
      "75721     877      381       4  882677345\n",
      "80184     815      602       3  878694269\n",
      "19864      94      431       4  891721716\n",
      "76699     416      875       2  876696938\n",
      "92991     500      182       2  883873556\n",
      "...       ...      ...     ...        ...\n",
      "21271     399      684       3  882344269\n",
      "34014     222      580       3  878715168\n",
      "81355     551      162       5  892783242\n",
      "65720     803      988       1  880055454\n",
      "11627      72      177       4  880037204\n",
      "\n",
      "[25000 rows x 4 columns]\n",
      "file is already exist\n",
      "/Users/sun/Desktop/NUS/CS5248/project/movie_recommdender/dinghui101/data/ml-1m/ratings.dat\n",
      "Size of Movielens 1m: (1000209, 4)\n",
      "        UserId  MovieId  Rating  Timestamp\n",
      "610738    3704     3784       3  966283775\n",
      "324752    1924      802       3  974694998\n",
      "808217    4837     1387       4  962891248\n",
      "133807     867     1196       4  975277040\n",
      "431857    2631     3072       5  973613453\n",
      "...        ...      ...     ...        ...\n",
      "259178    1586     1077       5  974735719\n",
      "365838    2129     2700       5  974643199\n",
      "131932     854     3102       3  975355597\n",
      "671155    4033     3479       5  965525805\n",
      "121958     786     1391       4  975429588\n",
      "\n",
      "[750156 rows x 4 columns]\n",
      "        UserId  MovieId  Rating   Timestamp\n",
      "895536    5412     2683       2   960243649\n",
      "899739    5440      904       5   959995181\n",
      "55687      368     3717       4   976311423\n",
      "63727      425     1721       4   976283587\n",
      "822011    4942     3697       1   962642480\n",
      "...        ...      ...     ...         ...\n",
      "840991    5054      927       5  1009574602\n",
      "149775     963      517       3   975120040\n",
      "539926    3320     3107       3   969216408\n",
      "563433    3467     1225       4   967160598\n",
      "428975    2611     3005       4   992890361\n",
      "\n",
      "[250053 rows x 4 columns]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 运行基准测试\n",
    "df_results = benchmark_recommenders(data_sizes, algorithms)\n",
    "print(df_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
