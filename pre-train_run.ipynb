{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloader import DataLoader as myDataLoader\n",
    "import torch\n",
    "from torch.utils.data import DataLoader as torchDataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Params settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA not available, using CPU\n"
     ]
    }
   ],
   "source": [
    "class Settings():\n",
    "    batch_size = 64\n",
    "    epochs = 200\n",
    "\n",
    "    embedding_size = 64\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    num_users = 471\n",
    "    num_items = 804\n",
    "\n",
    "    # Transformer encoder\n",
    "    dropout_rate = 0\n",
    "    num_heads = 4\n",
    "    d_ff = 4\n",
    "    num_blocks = 2\n",
    "\n",
    "\n",
    "    negative_num = 99\n",
    "    verbose = 1\n",
    "\n",
    "    hidden_dim = 256\n",
    "    user_epoch = 5\n",
    "    item_epoch = 25\n",
    "\n",
    "    second_user_epoch = 200\n",
    "    second_item_epoch = 200\n",
    "\n",
    "    third_user_epoch = 200\n",
    "    third_item_epoch = 200\n",
    "\n",
    "    train_user_dataset = './models/gnn_embedding/ml_gnn_ebd/initial_user_ebds.csv'\n",
    "    train_item_dataset = './models/gnn_embedding/ml_gnn_ebd/initial_item_ebds.csv'\n",
    "    valid_user_dataset = './models/gnn_embedding/ml_gnn_ebd/target_user_ebds.csv'\n",
    "    valid_item_dataset = './models/gnn_embedding/ml_gnn_ebd/target_item_ebds.csv'\n",
    "\n",
    "    dataset_size = '100k'\n",
    "\n",
    "    # set device\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Using CUDA (Nvidia GPU)\")\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        print(\"CUDA not available, using CPU\")\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "\n",
    "settings = Settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and searching for 1st 2nd 3rd order neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloader import DataLoader\n",
    "from utils.data_split import train_test_split\n",
    "\n",
    "# load the intial and target USER embedding for GNN training\n",
    "initial_user_embedding_path = \"./models/gnn_embedding/ml_gnn_ebd/initial_user_ebds.csv\"\n",
    "initial_item_embedding_path = \"./models/gnn_embedding/ml_gnn_ebd/initial_item_ebds.csv\"\n",
    "target_user_embedding_path = \"./models/gnn_embedding/ml_gnn_ebd/target_user_ebds.csv\"\n",
    "target_item_embedding_path = \"./models/gnn_embedding/ml_gnn_ebd/target_item_ebds.csv\"\n",
    "\n",
    "initial_user_embedding_df = pd.read_csv(initial_user_embedding_path)\n",
    "initial_item_embedding_df = pd.read_csv(initial_item_embedding_path)  \n",
    "target_user_embedding_df = pd.read_csv(target_user_embedding_path)\n",
    "target_item_embedding_df = pd.read_csv(target_item_embedding_path)\n",
    "\n",
    "# load the user movie rating dataframe\n",
    "movie_data = DataLoader(size=\"100k\")\n",
    "data = movie_data.load_ratings()\n",
    "ratings_df, test_set = train_test_split(data)\n",
    "train_ratings_df = ratings_df.copy()\n",
    "\n",
    "# create the user movie rating for trainning set\n",
    "user_ids = list(initial_user_embedding_df['user'].unique())\n",
    "item_ids = list(initial_item_embedding_df['item'].unique())\n",
    "ratings_df = ratings_df[ratings_df['user'].isin(user_ids) & ratings_df['item'].isin(item_ids)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1275\n",
      "55275\n"
     ]
    }
   ],
   "source": [
    "def build_user_item_graph(df):\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        user_node = f'u_{row[\"user\"]}'\n",
    "        item_node = f'i_{row[\"item\"]}'\n",
    "        G.add_edge(user_node, item_node)\n",
    "    \n",
    "    return G\n",
    "\n",
    "# generate the trainning graph\n",
    "G = build_user_item_graph(ratings_df)\n",
    "print(G.number_of_nodes())\n",
    "print(G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate high-order graph information\n",
    "def get_neighbors(graph, node):\n",
    "    first_order = list(graph.neighbors(node))\n",
    "    \n",
    "    # 2nd order neighbors\n",
    "    second_order = []\n",
    "    for first_neighbor in first_order:\n",
    "        second_order.extend(list(graph.neighbors(first_neighbor)))\n",
    "    second_order = list(set(second_order) - set(first_order) - {node})\n",
    "    \n",
    "    # 3rd order neighbors\n",
    "    third_order = []\n",
    "    for second_neighbor in second_order:\n",
    "        third_order.extend(list(graph.neighbors(second_neighbor)))\n",
    "    third_order = list(set(third_order) - set(first_order) - set(second_order) - {node})\n",
    "    \n",
    "    first_order = [int(n.split('_')[1]) for n in first_order]\n",
    "    second_order = [int(n.split('_')[1]) for n in second_order]\n",
    "    third_order = [int(n.split('_')[1]) for n in third_order]\n",
    "    \n",
    "    return [first_order, second_order, third_order]\n",
    "\n",
    "\n",
    "def compute_user_neighbors(user_graph, target_user_ids, target_embeddings_df):\n",
    "    data = []\n",
    "    for user_id in target_user_ids:\n",
    "        neighbors = get_neighbors(user_graph, f\"u_{user_id}\")\n",
    "        embedding = target_embeddings_df.loc[target_embeddings_df['user'] == user_id, 'embedding'].values[0]\n",
    "        data.append({\n",
    "            'userid': user_id,\n",
    "            '1st_order': neighbors[0],\n",
    "            '2nd_order': neighbors[1],\n",
    "            '3rd_order': neighbors[2],\n",
    "            'oracle_embedding': embedding\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def compute_item_neighbors(item_graph, target_item_ids, target_embeddings_df):\n",
    "    data = []\n",
    "    for item_id in target_item_ids:\n",
    "        neighbors = get_neighbors(item_graph, f\"i_{item_id}\")\n",
    "        embedding = target_embeddings_df.loc[target_embeddings_df['item'] == item_id, 'embedding'].values[0]\n",
    "        data.append({\n",
    "            'itemid': item_id,\n",
    "            '1st_order': neighbors[0],\n",
    "            '2nd_order': neighbors[1],\n",
    "            '3rd_order': neighbors[2],\n",
    "            'oracle_embedding': embedding\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the input data for user and item with high-order information\n",
    "target_user_input_df = compute_user_neighbors(G, user_ids, target_user_embedding_df)\n",
    "target_item_input_df = compute_item_neighbors(G, item_ids, target_item_embedding_df)\n",
    "\n",
    "# target_user_input_df.to_csv(\"./models/gnn_embedding/ml_gnn_ebd/gnn_user_input.csv\", index=False)\n",
    "# target_item_input_df.to_csv(\"./models/gnn_embedding/ml_gnn_ebd/gnn_item_input.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Trainning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train First Embedding with 1rd, 2nd, 3rd order user/item interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.gnn_embedding.GeneralGNN import GeneralGNN\n",
    "from models.gnn_embedding.train_helper_new import train_first_order_task, train_second_order_task, train_third_order_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the initial random embedding for user/item generated from init_embedding.ipynb\n",
    "\n",
    "init_user_embedding_path=\"./models/gnn_embedding/ml_gnn_ebd/initial_user_ebds.csv\"\n",
    "init_item_embedding_path=\"./models/gnn_embedding/ml_gnn_ebd/initial_item_ebds.csv\"\n",
    "\n",
    "model = GeneralGNN(name=\"GraphSAGE\", settings=settings, init_user_embedding_path=init_user_embedding_path,init_item_embedding_path=init_item_embedding_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Trainning Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for user tasks\n",
    "num_epochs = settings.epochs\n",
    "device = settings.device\n",
    "\n",
    "print(\"Training user tasks...\")\n",
    "print(\" -> Training 1st order user tasks...\")\n",
    "train_first_order_task(\n",
    "    model=model,\n",
    "    train_data=target_user_input_df,\n",
    "    epochs=num_epochs,\n",
    "    device=device,\n",
    "    task=\"user\",\n",
    ")\n",
    "\n",
    "print(\" -> Training 2nd order user tasks...\")\n",
    "train_second_order_task(\n",
    "    model=model,\n",
    "    train_data=target_user_input_df,\n",
    "    epochs=num_epochs,\n",
    "    device=device,\n",
    "    task=\"user\",\n",
    ")\n",
    "\n",
    "print(\" -> Training 3rd order user tasks...\")\n",
    "train_third_order_task(\n",
    "    model=model,\n",
    "    train_data=target_user_input_df,\n",
    "    epochs=num_epochs,\n",
    "    device=device,\n",
    "    task=\"user\",\n",
    ")\n",
    "\n",
    "# Train for item tasks\n",
    "print(\"Training item tasks...\")\n",
    "print(\" -> Training 1st order item tasks...\")\n",
    "train_first_order_task(\n",
    "    model=model,\n",
    "    train_data=target_item_input_df,\n",
    "    epochs=num_epochs,\n",
    "    device=device,\n",
    "    task=\"item\",\n",
    ")\n",
    "\n",
    "print(\" -> Training 2nd order item tasks...\")\n",
    "train_second_order_task(\n",
    "    model=model,\n",
    "    train_data=target_item_input_df,\n",
    "    epochs=num_epochs,\n",
    "    device=device,\n",
    "    task=\"item\",\n",
    ")\n",
    "\n",
    "print(\" -> Training 3rd order item tasks...\")\n",
    "train_third_order_task(\n",
    "    model=model,\n",
    "    train_data=target_item_input_df,\n",
    "    epochs=num_epochs,\n",
    "    device=device,\n",
    "    task=\"item\",\n",
    ")\n",
    "\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference - predict the embeddings for cold-start user/item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the initial embeddings for the full graph structure\n",
    "full_user_embedding_init_path = \"./models/gnn_embedding/ml_gnn_ebd/full_user_init_ebds.csv\"\n",
    "full_item_embedding_init_path = \"./models/gnn_embedding/ml_gnn_ebd/full_user_item_ebds.csv\"\n",
    "\n",
    "full_user_init_embedding = pd.read_csv(full_user_embedding_init_path)\n",
    "full_item_init_embedding = pd.read_csv(full_item_embedding_init_path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_user_ids = ratings_df['user'].unique()\n",
    "full_item_ids = ratings_df['item'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder all the data to align with every step of the model architecture\n",
    "movie_data = DataLoader(size=\"100k\")\n",
    "data = movie_data.load_ratings()\n",
    "train_list, test_list = train_test_split(data)\n",
    "ratings = pd.concat([train_list, test_list], axis=0, ignore_index=True)\n",
    "\n",
    "user_list = ratings['user'].unique().tolist()\n",
    "item_list = ratings['item'].unique().tolist()\n",
    "\n",
    "user2idx = {user: idx for idx, user in enumerate(user_list)}\n",
    "idx2user = {idx: user for user, idx in user2idx.items()}\n",
    "\n",
    "item2idx = {item:idx for idx, item in enumerate(item_list)}\n",
    "idx2item = {idx: item for item, idx in item2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_dataframe(df, user2idx,column):\n",
    "    \"\"\"\n",
    "    Reorder a DataFrame based on the user2idx mapping.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame with columns ['user', 'embedding'].\n",
    "        user2idx (dict): Dictionary mapping users to their new indices.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Reordered DataFrame with new indices based on user2idx.\n",
    "    \"\"\"\n",
    "    mapping = user2idx if column == 'user' else item2idx\n",
    "    # Shuffle the rows of the DataFrame\n",
    "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    # Map the 'user' column to the new index using user2idx\n",
    "    df['new_index'] = df[column].map(mapping)\n",
    "    \n",
    "    # Sort the DataFrame by the new index\n",
    "    df = df.sort_values(by='new_index').set_index('new_index')\n",
    "    \n",
    "    # Drop the 'new_index' column if you want only ['user', 'embedding']\n",
    "    df = df[[column, 'embedding']]\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_user_init_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder the full trainning item/user embedding to align with other parts of the model\n",
    "reordered_user_df = reorder_dataframe(full_user_init_embedding,user2idx,'user')\n",
    "reordered_item_df = reorder_dataframe(full_item_init_embedding,user2idx,'item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reordered_user_df.head(),reordered_item_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the reordered initial embedding for later reference\n",
    "import os\n",
    "\n",
    "output_folder = \"ml_gnn_ebd\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "reordered_user_df.to_csv(os.path.join(output_folder, \"full_initial_user_ebds.csv\"), index=False)\n",
    "reordered_item_df.to_csv(os.path.join(output_folder, \"full_initial_item_ebds.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the inputs for model inference, the inputs are generated in the notebook: ./models/gnn_embedding/init_embedding.ipynb\n",
    "\n",
    "full_init_item_ebd_path = \"./models/gnn_embedding/ml_gnn_ebd/full_initial_item_ebds.csv\"\n",
    "full_init_user_ebd_path = \"./models/gnn_embedding/ml_gnn_ebd/full_initial_user_ebds.csv\"\n",
    "model.reload_embedding(full_init_user_ebd_path,full_init_item_ebd_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# the final inference task to output the final inferred embeddings of all items/users in the trainning set\n",
    "def inference_3rd_task(model, train_data, device, task=\"user\"):\n",
    "    if (task == \"user\"):\n",
    "        target_ids_train = train_data[\"userid\"].tolist()\n",
    "    else:\n",
    "        target_ids_train = train_data[\"itemid\"].tolist()\n",
    "    support_1st_train = train_data[\"1st_order\"].tolist()\n",
    "    support_2nd_train = train_data[\"2nd_order\"].tolist()\n",
    "    support_3rd_train = train_data[\"3rd_order\"].tolist()\n",
    "\n",
    "    temp_embedding_list = train_data['oracle_embedding'].tolist()\n",
    "    if type(temp_embedding_list[0]) == str:\n",
    "        oracle_embeddings_train = torch.tensor([ast.literal_eval(s) for s in temp_embedding_list], dtype=torch.float32)\n",
    "    else:\n",
    "        oracle_embeddings_train = torch.tensor(temp_embedding_list, dtype=torch.float32)\n",
    "\n",
    "    oracle_embeddings_train = oracle_embeddings_train.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # 前向传播\n",
    "    all_predictions = torch.empty(0,oracle_embeddings_train.shape[1])\n",
    "    for i in range(0, len(target_ids_train)):\n",
    "        predicted_embeddings = model(target_ids_train[i], support_1st_train[i], support_2nd_train[i], support_3rd_train[i], task=task)\n",
    "        all_predictions = torch.cat((all_predictions, predicted_embeddings), dim = 0)\n",
    "    \n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2625\n",
      "75398\n"
     ]
    }
   ],
   "source": [
    "# craete the full graph for the tranning set\n",
    "full_G = build_user_item_graph(train_ratings_df)\n",
    "print(full_G.number_of_nodes())\n",
    "print(full_G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_user_ids = train_ratings_df['user'].unique()\n",
    "full_item_ids = train_ratings_df['item'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for inspection purpose only\n",
    "len(full_user_ids), len(full_item_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_user_init_embedding = pd.read_csv(full_init_user_ebd_path)\n",
    "full_item_init_embedding = pd.read_csv(full_init_item_ebd_path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_user_init_embedding.head(),full_item_init_embedding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the input dfs with high-order graph information\n",
    "inference_user_input_df = compute_user_neighbors(full_G, full_user_ids, full_user_init_embedding)\n",
    "inference_item_input_df = compute_item_neighbors(full_G, full_item_ids, full_item_init_embedding)\n",
    "\n",
    "# save the file for inspection and reference\n",
    "inference_user_input_df.to_csv(\"./models/gnn_embedding/ml_gnn_ebd/gnn_inference_user_input.csv\", index=False)\n",
    "inference_item_input_df.to_csv(\"./models/gnn_embedding/ml_gnn_ebd/gnn_inference_item_input.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The final inference result for all item/user embeddings\n",
    "inferred_user_embedding = inference_3rd_task(model,inference_user_input_df,\"cpu\",\"user\")\n",
    "inferred_item_embedding = inference_3rd_task(model,inference_item_input_df,\"cpu\",\"item\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_user_ebd_path = \"./data/pretrain_user_embeddings.pt\"\n",
    "pretrain_item_ebd_path = \"./data/pretrain_item_embeddings.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User embeddings saved to 'pretrain_user_embeddings.pt'\n"
     ]
    }
   ],
   "source": [
    "torch.save(inferred_user_embedding, pretrain_user_ebd_path)\n",
    "print(\"User embeddings saved to 'pretrain_user_embeddings.pt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item embeddings saved to 'pretrain_item_embeddings.pt'\n"
     ]
    }
   ],
   "source": [
    "torch.save(inferred_item_embedding, 'pretrain_item_embeddings.pt')\n",
    "print(\"Item embeddings saved to 'pretrain_item_embeddings.pt'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
