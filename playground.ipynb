{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Initial Encoding for User and Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaoyicong\\AppData\\Local\\Temp\\ipykernel_14392\\1724816224.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(\"genres_hot.pt\").size()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([9742, 20])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "torch.load(\"genres_hot.pt\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-07 16:17:27,140 - ClusGCN model - [INFO]: Using CPU\n",
      "2024-11-07 16:17:27,142 - ClusGCN model - [INFO]: Preparing data...\n",
      "2024-11-07 16:17:27,537 - ClusGCN model - [INFO]: Data Loaded.\n",
      "2024-11-07 16:17:28,078 - ClusGCN model - [INFO]: Generating negative samples...\n",
      "2024-11-07 16:17:28,711 - ClusGCN model - [INFO]: Generating negative samples...\n",
      "2024-11-07 16:17:28,851 - ClusGCN model - [INFO]: building graph...\n",
      "2024-11-07 16:17:28,877 - ClusGCN model - [INFO]: initilizing model...\n",
      "d:\\NUS\\CS5284_graph_ml\\project\\dinghui101\\models\\clus_gcn_model.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.genre_hot_embedding = torch.load(os.path.join(embedding_path, \"genre_hot_embedding.pt\"))\n",
      "d:\\NUS\\CS5284_graph_ml\\project\\dinghui101\\models\\clus_gcn_model.py:35: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.age_hot_embedding = torch.load(os.path.join(embedding_path, \"user_age_hot_embedding.pt\"))\n",
      "d:\\NUS\\CS5284_graph_ml\\project\\dinghui101\\models\\clus_gcn_model.py:36: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.occupation_hot_embedding = torch.load(os.path.join(embedding_path, \"user_occupation_hot_embedding.pt\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\xiaoyicong\\\\anaconda3\\\\envs\\\\dinghui101\\\\python310.zip', 'c:\\\\Users\\\\xiaoyicong\\\\anaconda3\\\\envs\\\\dinghui101\\\\DLLs', 'c:\\\\Users\\\\xiaoyicong\\\\anaconda3\\\\envs\\\\dinghui101\\\\lib', 'c:\\\\Users\\\\xiaoyicong\\\\anaconda3\\\\envs\\\\dinghui101', '', 'C:\\\\Users\\\\xiaoyicong\\\\AppData\\\\Roaming\\\\Python\\\\Python310\\\\site-packages', 'c:\\\\Users\\\\xiaoyicong\\\\anaconda3\\\\envs\\\\dinghui101\\\\lib\\\\site-packages', 'c:\\\\Users\\\\xiaoyicong\\\\anaconda3\\\\envs\\\\dinghui101\\\\lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\xiaoyicong\\\\anaconda3\\\\envs\\\\dinghui101\\\\lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\xiaoyicong\\\\anaconda3\\\\envs\\\\dinghui101\\\\lib\\\\site-packages\\\\Pythonwin', 'd:\\\\NUS\\\\CS5284_graph_ml\\\\project\\\\dinghui101']\n"
     ]
    }
   ],
   "source": [
    "from models.clus_gcn_model import ClusGCN, ClusGCNModel\n",
    "\n",
    "model_wrapper = ClusGCNModel(\n",
    "        size=\"100k\",\n",
    "        embedding_dim=64,\n",
    "        num_layers=5,\n",
    "        learning_rate=0.01,\n",
    "        epochs=50,\n",
    "        device='cpu'\n",
    "    )\n",
    "\n",
    "model_wrapper.prepare_training_data()\n",
    "\n",
    "ages2code = {\"Under 18\":0, \"18-24\":1, \"25-34\":2, \"35-44\":3, \"45-49\":4, \"50-55\":5, \"56+\":6}\n",
    "occupations2code = {\n",
    "        \"administrator\": 0,\n",
    "        \"artist\": 1,\n",
    "        \"doctor\": 2,\n",
    "        \"educator\": 3,\n",
    "        \"engineer\": 4,\n",
    "        \"entertainment\": 5,\n",
    "        \"executive\": 6,\n",
    "        \"healthcare\": 7,\n",
    "        \"homemaker\": 8,\n",
    "        \"lawyer\": 9,\n",
    "        \"librarian\": 10,\n",
    "        \"marketing\": 11,\n",
    "        \"none\": 12,\n",
    "        \"other\": 13,\n",
    "        \"programmer\": 14,\n",
    "        \"retired\": 15,\n",
    "        \"salesman\": 16,\n",
    "        \"scientist\": 17,\n",
    "        \"student\": 18,\n",
    "        \"technician\": 19,\n",
    "        \"writer\": 20\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_idx</th>\n",
       "      <th>item_idx</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>528</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>377</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>522</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>431</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495280</th>\n",
       "      <td>232</td>\n",
       "      <td>771</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495281</th>\n",
       "      <td>232</td>\n",
       "      <td>1433</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495282</th>\n",
       "      <td>232</td>\n",
       "      <td>1084</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495283</th>\n",
       "      <td>232</td>\n",
       "      <td>1275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495284</th>\n",
       "      <td>232</td>\n",
       "      <td>1563</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>495285 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_idx  item_idx  rating  label\n",
       "0              0         0       3      1\n",
       "1              0       528       4      1\n",
       "2              0       377       4      1\n",
       "3              0       522       3      1\n",
       "4              0       431       5      1\n",
       "...          ...       ...     ...    ...\n",
       "495280       232       771       0      0\n",
       "495281       232      1433       0      0\n",
       "495282       232      1084       0      0\n",
       "495283       232      1275       0      0\n",
       "495284       232      1563       0      0\n",
       "\n",
       "[495285 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wrapper.train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4715.000000\n",
       "mean        0.200000\n",
       "std         0.400042\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         1.000000\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wrapper.test_df[\"label\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    495285.0\n",
       "mean          0.2\n",
       "std           0.4\n",
       "min           0.0\n",
       "25%           0.0\n",
       "50%           0.0\n",
       "75%           0.0\n",
       "max           1.0\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wrapper.train_df[\"label\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99057.0, 943.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "495285/5, 4715/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ClusGCNModel' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ClusGCNModel' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "model_wrapper.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the row order of the movies\n",
    "# the order follows the \"index\" instead of the movie_id\n",
    "model_wrapper.items['sorting_index'] = model_wrapper.items['movie_id'].map(model_wrapper.item2idx)\n",
    "model_wrapper.items = model_wrapper.items.sort_values('sorting_index').drop(columns='sorting_index').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>genre_unknown</th>\n",
       "      <th>genre_Action</th>\n",
       "      <th>genre_Adventure</th>\n",
       "      <th>genre_Animation</th>\n",
       "      <th>genre_Children's</th>\n",
       "      <th>genre_Comedy</th>\n",
       "      <th>genre_Crime</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_Fantasy</th>\n",
       "      <th>genre_Film-Noir</th>\n",
       "      <th>genre_Horror</th>\n",
       "      <th>genre_Musical</th>\n",
       "      <th>genre_Mystery</th>\n",
       "      <th>genre_Romance</th>\n",
       "      <th>genre_Sci-Fi</th>\n",
       "      <th>genre_Thriller</th>\n",
       "      <th>genre_War</th>\n",
       "      <th>genre_Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>242</td>\n",
       "      <td>Kolya</td>\n",
       "      <td>1996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>302</td>\n",
       "      <td>L.A. Confidential</td>\n",
       "      <td>1997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>377</td>\n",
       "      <td>Heavyweights</td>\n",
       "      <td>1994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>Legends of the Fall</td>\n",
       "      <td>1994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>346</td>\n",
       "      <td>Jackie Brown</td>\n",
       "      <td>1997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>1674</td>\n",
       "      <td>Mamma Roma</td>\n",
       "      <td>1962</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>1640</td>\n",
       "      <td>Eighth Day, The</td>\n",
       "      <td>1996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>1637</td>\n",
       "      <td>Girls Town</td>\n",
       "      <td>1996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>1630</td>\n",
       "      <td>Silence of the Palace, The (Saimt el Qusur)</td>\n",
       "      <td>1994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>1641</td>\n",
       "      <td>Dadetown</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1682 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      movie_id                                        title  year  \\\n",
       "0          242                                        Kolya  1996   \n",
       "1          302                            L.A. Confidential  1997   \n",
       "2          377                                 Heavyweights  1994   \n",
       "3           51                          Legends of the Fall  1994   \n",
       "4          346                                 Jackie Brown  1997   \n",
       "...        ...                                          ...   ...   \n",
       "1677      1674                                   Mamma Roma  1962   \n",
       "1678      1640                              Eighth Day, The  1996   \n",
       "1679      1637                                   Girls Town  1996   \n",
       "1680      1630  Silence of the Palace, The (Saimt el Qusur)  1994   \n",
       "1681      1641                                     Dadetown  1995   \n",
       "\n",
       "      genre_unknown  genre_Action  genre_Adventure  genre_Animation  \\\n",
       "0                 0             0                0                0   \n",
       "1                 0             0                0                0   \n",
       "2                 0             0                0                0   \n",
       "3                 0             0                0                0   \n",
       "4                 0             0                0                0   \n",
       "...             ...           ...              ...              ...   \n",
       "1677              0             0                0                0   \n",
       "1678              0             0                0                0   \n",
       "1679              0             0                0                0   \n",
       "1680              0             0                0                0   \n",
       "1681              0             0                0                0   \n",
       "\n",
       "      genre_Children's  genre_Comedy  genre_Crime  ...  genre_Fantasy  \\\n",
       "0                    0             1            0  ...              0   \n",
       "1                    0             0            1  ...              0   \n",
       "2                    1             1            0  ...              0   \n",
       "3                    0             0            0  ...              0   \n",
       "4                    0             0            1  ...              0   \n",
       "...                ...           ...          ...  ...            ...   \n",
       "1677                 0             0            0  ...              0   \n",
       "1678                 0             0            0  ...              0   \n",
       "1679                 0             0            0  ...              0   \n",
       "1680                 0             0            0  ...              0   \n",
       "1681                 0             0            0  ...              0   \n",
       "\n",
       "      genre_Film-Noir  genre_Horror  genre_Musical  genre_Mystery  \\\n",
       "0                   0             0              0              0   \n",
       "1                   1             0              0              1   \n",
       "2                   0             0              0              0   \n",
       "3                   0             0              0              0   \n",
       "4                   0             0              0              0   \n",
       "...               ...           ...            ...            ...   \n",
       "1677                0             0              0              0   \n",
       "1678                0             0              0              0   \n",
       "1679                0             0              0              0   \n",
       "1680                0             0              0              0   \n",
       "1681                0             0              0              0   \n",
       "\n",
       "      genre_Romance  genre_Sci-Fi  genre_Thriller  genre_War  genre_Western  \n",
       "0                 0             0               0          0              0  \n",
       "1                 0             0               1          0              0  \n",
       "2                 0             0               0          0              0  \n",
       "3                 1             0               0          1              1  \n",
       "4                 0             0               0          0              0  \n",
       "...             ...           ...             ...        ...            ...  \n",
       "1677              0             0               0          0              0  \n",
       "1678              0             0               0          0              0  \n",
       "1679              0             0               0          0              0  \n",
       "1680              0             0               0          0              0  \n",
       "1681              0             0               0          0              0  \n",
       "\n",
       "[1682 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wrapper.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['genre_unknown', 'genre_Action', 'genre_Adventure', 'genre_Animation',\n",
       "       'genre_Children's', 'genre_Comedy', 'genre_Crime', 'genre_Documentary',\n",
       "       'genre_Drama', 'genre_Fantasy', 'genre_Film-Noir', 'genre_Horror',\n",
       "       'genre_Musical', 'genre_Mystery', 'genre_Romance', 'genre_Sci-Fi',\n",
       "       'genre_Thriller', 'genre_War', 'genre_Western'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_columns = model_wrapper.items.columns[-19:]\n",
    "genre_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_values = model_wrapper.items[genre_columns].values\n",
    "genre_tensor = torch.tensor(genre_values, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1682, 19])\n"
     ]
    }
   ],
   "source": [
    "print(genre_tensor.shape)\n",
    "torch.save(genre_tensor, 'genre_hot_embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>18-24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>50-55</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>94043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>18-24</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>18-24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>43537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>25-34</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>15213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>939</td>\n",
       "      <td>25-34</td>\n",
       "      <td>F</td>\n",
       "      <td>student</td>\n",
       "      <td>33319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>940</td>\n",
       "      <td>25-34</td>\n",
       "      <td>M</td>\n",
       "      <td>administrator</td>\n",
       "      <td>02215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>941</td>\n",
       "      <td>18-24</td>\n",
       "      <td>M</td>\n",
       "      <td>student</td>\n",
       "      <td>97229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>942</td>\n",
       "      <td>45-49</td>\n",
       "      <td>F</td>\n",
       "      <td>librarian</td>\n",
       "      <td>78209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>943</td>\n",
       "      <td>18-24</td>\n",
       "      <td>M</td>\n",
       "      <td>student</td>\n",
       "      <td>77841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     userid    age gender     occupation zipcode\n",
       "0         1  18-24      M     technician   85711\n",
       "1         2  50-55      F          other   94043\n",
       "2         3  18-24      M         writer   32067\n",
       "3         4  18-24      M     technician   43537\n",
       "4         5  25-34      F          other   15213\n",
       "..      ...    ...    ...            ...     ...\n",
       "938     939  25-34      F        student   33319\n",
       "939     940  25-34      M  administrator   02215\n",
       "940     941  18-24      M        student   97229\n",
       "941     942  45-49      F      librarian   78209\n",
       "942     943  18-24      M        student   77841\n",
       "\n",
       "[943 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wrapper.user_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Users\n",
    "model_wrapper.user_features['sorting_index'] = model_wrapper.user_features['userid'].map(model_wrapper.user2idx)\n",
    "model_wrapper.user_features = model_wrapper.user_features.sort_values('sorting_index').drop(columns='sorting_index').reset_index(drop=True)\n",
    "\n",
    "# Generate one-hot encoding for age\n",
    "age_encoding = torch.zeros(len(model_wrapper.user_features), len(ages2code))\n",
    "for i, age_range in enumerate(model_wrapper.user_features['age']):\n",
    "    age_encoding[i][ages2code[age_range]] = 1\n",
    "\n",
    "# Generate one-hot encoding for occupation\n",
    "occupation_encoding = torch.zeros(len(model_wrapper.user_features), len(occupations2code))\n",
    "for i, occupation in enumerate(model_wrapper.user_features['occupation']):\n",
    "    occupation_encoding[i][occupations2code[occupation]] = 1\n",
    "\n",
    "# Save the encodings to .pt files\n",
    "torch.save(age_encoding, 'user_age_hot_embedding.pt')\n",
    "torch.save(occupation_encoding, 'user_occupation_hot_embedding.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([943, 7]), torch.Size([943, 21]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_encoding.size(), occupation_encoding.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user  item  rating  timestamp  user_idx  item_idx\n",
      "59165   196   762       3  881251955         0       365\n",
      "       user  item  rating  timestamp  user_idx  item_idx\n",
      "0       196   242       3  881250949         0         0\n",
      "940     196   393       4  881251863         0       528\n",
      "1133    196   381       4  881251728         0       377\n",
      "1812    196   251       3  881251274         0       522\n",
      "1896    196   655       5  881251793         0       431\n",
      "2374    196    67       5  881252017         0       834\n",
      "6910    196   306       4  881251021         0       380\n",
      "7517    196   238       4  881251820         0       329\n",
      "7842    196   663       5  881251911         0       550\n",
      "10017   196   111       4  881251793         0        83\n",
      "10254   196   580       2  881252056         0       632\n",
      "10981   196    25       4  881251955         0        86\n",
      "13733   196   286       5  881250949         0       289\n",
      "14606   196    94       3  881252172         0       363\n",
      "16834   196   692       5  881252017         0       438\n",
      "17102   196     8       5  881251753         0       389\n",
      "17830   196   428       4  881251702         0       649\n",
      "18853   196  1118       4  881252128         0       947\n",
      "21605   196    70       3  881251842         0       423\n",
      "22271   196    66       3  881251911         0       291\n",
      "22773   196   257       2  881251577         0        10\n",
      "23189   196   108       4  881252110         0      1006\n",
      "24030   196   202       3  881251728         0       179\n",
      "25726   196   340       3  881251045         0       751\n",
      "32721   196   287       3  881251884         0       487\n",
      "33536   196   116       3  881251753         0       665\n",
      "35197   196   382       4  881251843         0        92\n",
      "36281   196   285       5  881251753         0       512\n",
      "41539   196  1241       3  881251642         0      1045\n",
      "42384   196  1007       4  881251601         0       672\n",
      "50147   196   411       4  881252090         0       656\n",
      "52726   196   153       5  881251820         0       221\n",
      "56628   196    13       2  881251955         0       432\n",
      "59607   196   173       2  881251820         0       321\n",
      "60199   196  1022       4  881251143         0       466\n",
      "60706   196   845       4  881251954         0       302\n",
      "78787   196   269       3  881250949         0       491\n",
      "87863   196   110       1  881252305         0       521\n"
     ]
    }
   ],
   "source": [
    "grouped = model_wrapper.ratings.groupby('user_idx')\n",
    "\n",
    "for user, group in grouped:\n",
    "    #print(user)\n",
    "    #print(group)\n",
    "    test_sample = group.sample(n=1, random_state=42)\n",
    "    train_sample = group.drop(test_sample.index)\n",
    "    print(test_sample)\n",
    "    print(train_sample)\n",
    "    break\n",
    "    # if len(group) < 2:\n",
    "    #     train_list.append(group)\n",
    "    # else:\n",
    "    #     test_sample = group.sample(n=1, random_state=42)\n",
    "    #     train_sample = group.drop(test_sample.index)\n",
    "    #     train_list.append(train_sample)\n",
    "    #     test_list.append(test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-01 01:58:02,363 - LGCN model - [INFO]: Using CPU\n",
      "2024-11-01 01:58:02,369 - LGCN model - [INFO]: Preparing data...\n",
      "2024-11-01 01:58:02,731 - LGCN model - [INFO]: Data Loaded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user  item  rating  timestamp\n",
      "0   196   242       3  881250949\n",
      "1   186   302       3  891717742\n",
      "2    22   377       1  878887116\n",
      "3   244    51       2  880606923\n",
      "4   166   346       1  886397596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-01 01:58:03,250 - LGCN model - [INFO]: Generating negative samples...\n",
      "2024-11-01 01:58:03,789 - LGCN model - [INFO]: Generating negative samples...\n",
      "2024-11-01 01:58:03,922 - LGCN model - [INFO]: building graph...\n",
      "2024-11-01 01:58:03,944 - LGCN model - [INFO]: initilizing model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adj_norm: tensor(indices=tensor([[   0,    0,    0,  ..., 2622, 2623, 2624],\n",
      "                       [ 943,  953, 1026,  ...,  650,  650,  650]]),\n",
      "       values=tensor([0.0151, 0.0094, 0.0099,  ..., 0.0382, 0.0382, 0.0382]),\n",
      "       size=(2625, 2625), nnz=198114, layout=torch.sparse_coo)\n",
      "['c:\\\\Users\\\\xiaoyicong\\\\anaconda3\\\\envs\\\\dinghui101\\\\python310.zip', 'c:\\\\Users\\\\xiaoyicong\\\\anaconda3\\\\envs\\\\dinghui101\\\\DLLs', 'c:\\\\Users\\\\xiaoyicong\\\\anaconda3\\\\envs\\\\dinghui101\\\\lib', 'c:\\\\Users\\\\xiaoyicong\\\\anaconda3\\\\envs\\\\dinghui101', '', 'C:\\\\Users\\\\xiaoyicong\\\\AppData\\\\Roaming\\\\Python\\\\Python310\\\\site-packages', 'c:\\\\Users\\\\xiaoyicong\\\\anaconda3\\\\envs\\\\dinghui101\\\\lib\\\\site-packages', 'c:\\\\Users\\\\xiaoyicong\\\\anaconda3\\\\envs\\\\dinghui101\\\\lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\xiaoyicong\\\\anaconda3\\\\envs\\\\dinghui101\\\\lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\xiaoyicong\\\\anaconda3\\\\envs\\\\dinghui101\\\\lib\\\\site-packages\\\\Pythonwin', 'd:\\\\NUS\\\\CS5284_graph_ml\\\\project\\\\dinghui101']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\NUS\\CS5284_graph_ml\\project\\dinghui101\\models\\clus_gcn_model.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.genre_hot_embedding = torch.load(os.path.join(embedding_path, \"genre_hot_embedding.pt\"))\n",
      "d:\\NUS\\CS5284_graph_ml\\project\\dinghui101\\models\\clus_gcn_model.py:35: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.age_hot_embedding = torch.load(os.path.join(embedding_path, \"user_age_hot_embedding.pt\"))\n",
      "d:\\NUS\\CS5284_graph_ml\\project\\dinghui101\\models\\clus_gcn_model.py:36: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.occupation_hot_embedding = torch.load(os.path.join(embedding_path, \"user_occupation_hot_embedding.pt\"))\n"
     ]
    }
   ],
   "source": [
    "from models.clus_gcn_model import ClusGCN, ClusGCNModel\n",
    "\n",
    "model_wrapper = ClusGCNModel(\n",
    "        size=\"100k\",\n",
    "        embedding_dim=64,\n",
    "        num_layers=5,\n",
    "        learning_rate=0.01,\n",
    "        epochs=50,\n",
    "        device='cpu'\n",
    "    )\n",
    "\n",
    "model_wrapper.prepare_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClusGCN(\n",
       "  (user_embedding): Embedding(943, 64)\n",
       "  (item_embedding): Embedding(1682, 64)\n",
       "  (genre_cat_layer): Linear(in_features=19, out_features=64, bias=True)\n",
       "  (age_cat_layer): Linear(in_features=7, out_features=64, bias=True)\n",
       "  (occupation_cat_layer): Linear(in_features=21, out_features=64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wrapper.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([943, 64]), torch.Size([1682, 64]), torch.Size([2625, 64]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_wrapper.model\n",
    "all_embeddings = torch.cat(\n",
    "            [model.user_embedding.weight, \n",
    "             model.item_embedding.weight], dim=0\n",
    "        )\n",
    "model.user_embedding.weight.size(), model.item_embedding.weight.size(), all_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(943, 64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.user_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 38,\n",
       " 1: 91,\n",
       " 2: 127,\n",
       " 3: 237,\n",
       " 4: 19,\n",
       " 5: 126,\n",
       " 6: 91,\n",
       " 7: 96,\n",
       " 8: 221,\n",
       " 9: 210,\n",
       " 10: 231,\n",
       " 11: 287,\n",
       " 12: 215,\n",
       " 13: 131,\n",
       " 14: 140,\n",
       " 15: 483,\n",
       " 16: 60,\n",
       " 17: 304,\n",
       " 18: 295,\n",
       " 19: 479,\n",
       " 20: 180,\n",
       " 21: 68,\n",
       " 22: 279,\n",
       " 23: 396,\n",
       " 24: 277,\n",
       " 25: 120,\n",
       " 26: 215,\n",
       " 27: 92,\n",
       " 28: 119,\n",
       " 29: 23,\n",
       " 30: 274,\n",
       " 31: 26,\n",
       " 32: 149,\n",
       " 33: 62,\n",
       " 34: 50,\n",
       " 35: 434,\n",
       " 36: 22,\n",
       " 37: 517,\n",
       " 38: 402,\n",
       " 39: 183,\n",
       " 40: 46,\n",
       " 41: 385,\n",
       " 42: 61,\n",
       " 43: 194,\n",
       " 44: 19,\n",
       " 45: 160,\n",
       " 46: 135,\n",
       " 47: 272,\n",
       " 48: 76,\n",
       " 49: 57,\n",
       " 50: 23,\n",
       " 51: 77,\n",
       " 52: 381,\n",
       " 53: 136,\n",
       " 54: 210,\n",
       " 55: 182,\n",
       " 56: 123,\n",
       " 57: 47,\n",
       " 58: 635,\n",
       " 59: 50,\n",
       " 60: 207,\n",
       " 61: 105,\n",
       " 62: 104,\n",
       " 63: 186,\n",
       " 64: 80,\n",
       " 65: 387,\n",
       " 66: 22,\n",
       " 67: 158,\n",
       " 68: 387,\n",
       " 69: 22,\n",
       " 70: 386,\n",
       " 71: 184,\n",
       " 72: 180,\n",
       " 73: 58,\n",
       " 74: 41,\n",
       " 75: 433,\n",
       " 76: 315,\n",
       " 77: 78,\n",
       " 78: 54,\n",
       " 79: 40,\n",
       " 80: 299,\n",
       " 81: 130,\n",
       " 82: 121,\n",
       " 83: 277,\n",
       " 84: 45,\n",
       " 85: 180,\n",
       " 86: 68,\n",
       " 87: 132,\n",
       " 88: 153,\n",
       " 89: 47,\n",
       " 90: 399,\n",
       " 91: 183,\n",
       " 92: 150,\n",
       " 93: 119,\n",
       " 94: 51,\n",
       " 95: 167,\n",
       " 96: 159,\n",
       " 97: 176,\n",
       " 98: 220,\n",
       " 99: 67,\n",
       " 100: 322,\n",
       " 101: 45,\n",
       " 102: 287,\n",
       " 103: 125,\n",
       " 104: 73,\n",
       " 105: 214,\n",
       " 106: 21,\n",
       " 107: 33,\n",
       " 108: 26,\n",
       " 109: 19,\n",
       " 110: 327,\n",
       " 111: 174,\n",
       " 112: 28,\n",
       " 113: 37,\n",
       " 114: 276,\n",
       " 115: 106,\n",
       " 116: 352,\n",
       " 117: 206,\n",
       " 118: 271,\n",
       " 119: 186,\n",
       " 120: 103,\n",
       " 121: 229,\n",
       " 122: 92,\n",
       " 123: 55,\n",
       " 124: 57,\n",
       " 125: 64,\n",
       " 126: 181,\n",
       " 127: 154,\n",
       " 128: 50,\n",
       " 129: 306,\n",
       " 130: 64,\n",
       " 131: 139,\n",
       " 132: 97,\n",
       " 133: 149,\n",
       " 134: 29,\n",
       " 135: 19,\n",
       " 136: 130,\n",
       " 137: 97,\n",
       " 138: 195,\n",
       " 139: 109,\n",
       " 140: 127,\n",
       " 141: 34,\n",
       " 142: 58,\n",
       " 143: 111,\n",
       " 144: 191,\n",
       " 145: 120,\n",
       " 146: 50,\n",
       " 147: 94,\n",
       " 148: 27,\n",
       " 149: 52,\n",
       " 150: 53,\n",
       " 151: 172,\n",
       " 152: 20,\n",
       " 153: 150,\n",
       " 154: 146,\n",
       " 155: 23,\n",
       " 156: 50,\n",
       " 157: 71,\n",
       " 158: 137,\n",
       " 159: 55,\n",
       " 160: 21,\n",
       " 161: 66,\n",
       " 162: 250,\n",
       " 163: 45,\n",
       " 164: 25,\n",
       " 165: 92,\n",
       " 166: 64,\n",
       " 167: 110,\n",
       " 168: 23,\n",
       " 169: 205,\n",
       " 170: 26,\n",
       " 171: 20,\n",
       " 172: 32,\n",
       " 173: 114,\n",
       " 174: 42,\n",
       " 175: 178,\n",
       " 176: 117,\n",
       " 177: 24,\n",
       " 178: 62,\n",
       " 179: 123,\n",
       " 180: 122,\n",
       " 181: 233,\n",
       " 182: 199,\n",
       " 183: 47,\n",
       " 184: 158,\n",
       " 185: 85,\n",
       " 186: 79,\n",
       " 187: 46,\n",
       " 188: 56,\n",
       " 189: 23,\n",
       " 190: 31,\n",
       " 191: 55,\n",
       " 192: 142,\n",
       " 193: 65,\n",
       " 194: 145,\n",
       " 195: 93,\n",
       " 196: 62,\n",
       " 197: 25,\n",
       " 198: 27,\n",
       " 199: 29,\n",
       " 200: 47,\n",
       " 201: 29,\n",
       " 202: 132,\n",
       " 203: 44,\n",
       " 204: 20,\n",
       " 205: 257,\n",
       " 206: 74,\n",
       " 207: 105,\n",
       " 208: 75,\n",
       " 209: 54,\n",
       " 210: 78,\n",
       " 211: 21,\n",
       " 212: 21,\n",
       " 213: 20,\n",
       " 214: 70,\n",
       " 215: 52,\n",
       " 216: 27,\n",
       " 217: 21,\n",
       " 218: 49,\n",
       " 219: 31,\n",
       " 220: 42,\n",
       " 221: 47,\n",
       " 222: 31,\n",
       " 223: 70,\n",
       " 224: 111,\n",
       " 225: 65,\n",
       " 226: 293,\n",
       " 227: 29,\n",
       " 228: 32,\n",
       " 229: 61,\n",
       " 230: 21,\n",
       " 231: 55,\n",
       " 232: 19,\n",
       " 233: 106,\n",
       " 234: 28,\n",
       " 235: 33,\n",
       " 236: 36,\n",
       " 237: 56,\n",
       " 238: 106,\n",
       " 239: 95,\n",
       " 240: 32,\n",
       " 241: 24,\n",
       " 242: 82,\n",
       " 243: 75,\n",
       " 244: 20,\n",
       " 245: 58,\n",
       " 246: 67,\n",
       " 247: 27,\n",
       " 248: 261,\n",
       " 249: 27,\n",
       " 250: 23,\n",
       " 251: 35,\n",
       " 252: 62,\n",
       " 253: 63,\n",
       " 254: 222,\n",
       " 255: 37,\n",
       " 256: 22,\n",
       " 257: 21,\n",
       " 258: 19,\n",
       " 259: 39,\n",
       " 260: 19,\n",
       " 261: 53,\n",
       " 262: 63,\n",
       " 263: 81,\n",
       " 264: 244,\n",
       " 265: 34,\n",
       " 266: 41,\n",
       " 267: 23,\n",
       " 268: 25,\n",
       " 269: 53,\n",
       " 270: 57,\n",
       " 271: 20,\n",
       " 272: 24,\n",
       " 273: 20,\n",
       " 274: 24,\n",
       " 275: 19,\n",
       " 276: 22,\n",
       " 277: 19,\n",
       " 278: 37,\n",
       " 279: 22,\n",
       " 280: 41,\n",
       " 281: 86,\n",
       " 282: 35,\n",
       " 283: 74,\n",
       " 284: 28,\n",
       " 285: 173,\n",
       " 286: 42,\n",
       " 287: 25,\n",
       " 288: 26,\n",
       " 289: 26,\n",
       " 290: 32,\n",
       " 291: 26,\n",
       " 292: 20,\n",
       " 293: 21,\n",
       " 294: 25,\n",
       " 295: 124,\n",
       " 296: 22,\n",
       " 297: 38,\n",
       " 298: 28,\n",
       " 299: 22,\n",
       " 300: 88,\n",
       " 301: 29,\n",
       " 302: 36,\n",
       " 303: 26,\n",
       " 304: 50,\n",
       " 305: 34,\n",
       " 306: 22,\n",
       " 307: 20,\n",
       " 308: 141,\n",
       " 309: 153,\n",
       " 310: 186,\n",
       " 311: 283,\n",
       " 312: 52,\n",
       " 313: 282,\n",
       " 314: 50,\n",
       " 315: 146,\n",
       " 316: 24,\n",
       " 317: 69,\n",
       " 318: 182,\n",
       " 319: 64,\n",
       " 320: 22,\n",
       " 321: 23,\n",
       " 322: 19,\n",
       " 323: 22,\n",
       " 324: 25,\n",
       " 325: 332,\n",
       " 326: 21,\n",
       " 327: 65,\n",
       " 328: 21,\n",
       " 329: 129,\n",
       " 330: 21,\n",
       " 331: 36,\n",
       " 332: 74,\n",
       " 333: 253,\n",
       " 334: 19,\n",
       " 335: 200,\n",
       " 336: 43,\n",
       " 337: 21,\n",
       " 338: 20,\n",
       " 339: 236,\n",
       " 340: 189,\n",
       " 341: 231,\n",
       " 342: 192,\n",
       " 343: 198,\n",
       " 344: 21,\n",
       " 345: 20,\n",
       " 346: 40,\n",
       " 347: 57,\n",
       " 348: 232,\n",
       " 349: 43,\n",
       " 350: 42,\n",
       " 351: 41,\n",
       " 352: 101,\n",
       " 353: 310,\n",
       " 354: 25,\n",
       " 355: 24,\n",
       " 356: 75,\n",
       " 357: 23,\n",
       " 358: 120,\n",
       " 359: 57,\n",
       " 360: 49,\n",
       " 361: 57,\n",
       " 362: 44,\n",
       " 363: 50,\n",
       " 364: 232,\n",
       " 365: 74,\n",
       " 366: 273,\n",
       " 367: 65,\n",
       " 368: 33,\n",
       " 369: 374,\n",
       " 370: 32,\n",
       " 371: 32,\n",
       " 372: 27,\n",
       " 373: 26,\n",
       " 374: 195,\n",
       " 375: 161,\n",
       " 376: 126,\n",
       " 377: 280,\n",
       " 378: 52,\n",
       " 379: 303,\n",
       " 380: 19,\n",
       " 381: 21,\n",
       " 382: 51,\n",
       " 383: 22,\n",
       " 384: 270,\n",
       " 385: 70,\n",
       " 386: 30,\n",
       " 387: 447,\n",
       " 388: 110,\n",
       " 389: 29,\n",
       " 390: 148,\n",
       " 391: 120,\n",
       " 392: 171,\n",
       " 393: 101,\n",
       " 394: 318,\n",
       " 395: 53,\n",
       " 396: 152,\n",
       " 397: 67,\n",
       " 398: 21,\n",
       " 399: 56,\n",
       " 400: 24,\n",
       " 401: 49,\n",
       " 402: 736,\n",
       " 403: 21,\n",
       " 404: 341,\n",
       " 405: 225,\n",
       " 406: 202,\n",
       " 407: 43,\n",
       " 408: 49,\n",
       " 409: 492,\n",
       " 410: 26,\n",
       " 411: 27,\n",
       " 412: 57,\n",
       " 413: 364,\n",
       " 414: 50,\n",
       " 415: 35,\n",
       " 416: 96,\n",
       " 417: 203,\n",
       " 418: 31,\n",
       " 419: 23,\n",
       " 420: 63,\n",
       " 421: 413,\n",
       " 422: 54,\n",
       " 423: 30,\n",
       " 424: 19,\n",
       " 425: 43,\n",
       " 426: 61,\n",
       " 427: 61,\n",
       " 428: 378,\n",
       " 429: 40,\n",
       " 430: 100,\n",
       " 431: 144,\n",
       " 432: 64,\n",
       " 433: 43,\n",
       " 434: 262,\n",
       " 435: 32,\n",
       " 436: 20,\n",
       " 437: 142,\n",
       " 438: 50,\n",
       " 439: 134,\n",
       " 440: 138,\n",
       " 441: 74,\n",
       " 442: 539,\n",
       " 443: 35,\n",
       " 444: 30,\n",
       " 445: 97,\n",
       " 446: 205,\n",
       " 447: 235,\n",
       " 448: 155,\n",
       " 449: 24,\n",
       " 450: 188,\n",
       " 451: 23,\n",
       " 452: 37,\n",
       " 453: 276,\n",
       " 454: 216,\n",
       " 455: 182,\n",
       " 456: 32,\n",
       " 457: 117,\n",
       " 458: 67,\n",
       " 459: 22,\n",
       " 460: 43,\n",
       " 461: 142,\n",
       " 462: 100,\n",
       " 463: 262,\n",
       " 464: 79,\n",
       " 465: 132,\n",
       " 466: 30,\n",
       " 467: 326,\n",
       " 468: 42,\n",
       " 469: 52,\n",
       " 470: 82,\n",
       " 471: 112,\n",
       " 472: 34,\n",
       " 473: 56,\n",
       " 474: 59,\n",
       " 475: 19,\n",
       " 476: 201,\n",
       " 477: 138,\n",
       " 478: 188,\n",
       " 479: 230,\n",
       " 480: 25,\n",
       " 481: 55,\n",
       " 482: 54,\n",
       " 483: 134,\n",
       " 484: 56,\n",
       " 485: 108,\n",
       " 486: 58,\n",
       " 487: 128,\n",
       " 488: 46,\n",
       " 489: 212,\n",
       " 490: 34,\n",
       " 491: 278,\n",
       " 492: 153,\n",
       " 493: 148,\n",
       " 494: 101,\n",
       " 495: 32,\n",
       " 496: 224,\n",
       " 497: 36,\n",
       " 498: 159,\n",
       " 499: 250,\n",
       " 500: 111,\n",
       " 501: 241,\n",
       " 502: 23,\n",
       " 503: 57,\n",
       " 504: 193,\n",
       " 505: 86,\n",
       " 506: 23,\n",
       " 507: 39,\n",
       " 508: 20,\n",
       " 509: 21,\n",
       " 510: 19,\n",
       " 511: 99,\n",
       " 512: 72,\n",
       " 513: 32,\n",
       " 514: 20,\n",
       " 515: 29,\n",
       " 516: 305,\n",
       " 517: 72,\n",
       " 518: 53,\n",
       " 519: 149,\n",
       " 520: 22,\n",
       " 521: 48,\n",
       " 522: 52,\n",
       " 523: 273,\n",
       " 524: 44,\n",
       " 525: 29,\n",
       " 526: 42,\n",
       " 527: 36,\n",
       " 528: 136,\n",
       " 529: 25,\n",
       " 530: 259,\n",
       " 531: 217,\n",
       " 532: 162,\n",
       " 533: 67,\n",
       " 534: 489,\n",
       " 535: 79,\n",
       " 536: 132,\n",
       " 537: 80,\n",
       " 538: 134,\n",
       " 539: 161,\n",
       " 540: 55,\n",
       " 541: 22,\n",
       " 542: 196,\n",
       " 543: 154,\n",
       " 544: 58,\n",
       " 545: 29,\n",
       " 546: 333,\n",
       " 547: 30,\n",
       " 548: 99,\n",
       " 549: 83,\n",
       " 550: 62,\n",
       " 551: 113,\n",
       " 552: 39,\n",
       " 553: 43,\n",
       " 554: 75,\n",
       " 555: 100,\n",
       " 556: 356,\n",
       " 557: 29,\n",
       " 558: 148,\n",
       " 559: 52,\n",
       " 560: 19,\n",
       " 561: 33,\n",
       " 562: 34,\n",
       " 563: 50,\n",
       " 564: 24,\n",
       " 565: 154,\n",
       " 566: 69,\n",
       " 567: 71,\n",
       " 568: 35,\n",
       " 569: 187,\n",
       " 570: 73,\n",
       " 571: 45,\n",
       " 572: 51,\n",
       " 573: 19,\n",
       " 574: 25,\n",
       " 575: 23,\n",
       " 576: 224,\n",
       " 577: 97,\n",
       " 578: 80,\n",
       " 579: 165,\n",
       " 580: 79,\n",
       " 581: 61,\n",
       " 582: 83,\n",
       " 583: 27,\n",
       " 584: 359,\n",
       " 585: 46,\n",
       " 586: 47,\n",
       " 587: 155,\n",
       " 588: 26,\n",
       " 589: 19,\n",
       " 590: 21,\n",
       " 591: 46,\n",
       " 592: 42,\n",
       " 593: 24,\n",
       " 594: 40,\n",
       " 595: 23,\n",
       " 596: 147,\n",
       " 597: 28,\n",
       " 598: 88,\n",
       " 599: 89,\n",
       " 600: 46,\n",
       " 601: 95,\n",
       " 602: 235,\n",
       " 603: 162,\n",
       " 604: 36,\n",
       " 605: 74,\n",
       " 606: 41,\n",
       " 607: 107,\n",
       " 608: 215,\n",
       " 609: 38,\n",
       " 610: 27,\n",
       " 611: 102,\n",
       " 612: 42,\n",
       " 613: 109,\n",
       " 614: 19,\n",
       " 615: 88,\n",
       " 616: 27,\n",
       " 617: 227,\n",
       " 618: 170,\n",
       " 619: 26,\n",
       " 620: 140,\n",
       " 621: 26,\n",
       " 622: 180,\n",
       " 623: 44,\n",
       " 624: 26,\n",
       " 625: 105,\n",
       " 626: 120,\n",
       " 627: 57,\n",
       " 628: 117,\n",
       " 629: 19,\n",
       " 630: 134,\n",
       " 631: 147,\n",
       " 632: 107,\n",
       " 633: 317,\n",
       " 634: 103,\n",
       " 635: 108,\n",
       " 636: 31,\n",
       " 637: 205,\n",
       " 638: 24,\n",
       " 639: 66,\n",
       " 640: 33,\n",
       " 641: 41,\n",
       " 642: 19,\n",
       " 643: 121,\n",
       " 644: 296,\n",
       " 645: 57,\n",
       " 646: 310,\n",
       " 647: 20,\n",
       " 648: 146,\n",
       " 649: 282,\n",
       " 650: 684,\n",
       " 651: 23,\n",
       " 652: 70,\n",
       " 653: 23,\n",
       " 654: 223,\n",
       " 655: 190,\n",
       " 656: 37,\n",
       " 657: 157,\n",
       " 658: 165,\n",
       " 659: 28,\n",
       " 660: 141,\n",
       " 661: 244,\n",
       " 662: 120,\n",
       " 663: 22,\n",
       " 664: 46,\n",
       " 665: 39,\n",
       " 666: 45,\n",
       " 667: 34,\n",
       " 668: 123,\n",
       " 669: 99,\n",
       " 670: 76,\n",
       " 671: 40,\n",
       " 672: 21,\n",
       " 673: 48,\n",
       " 674: 398,\n",
       " 675: 61,\n",
       " 676: 85,\n",
       " 677: 19,\n",
       " 678: 74,\n",
       " 679: 31,\n",
       " 680: 28,\n",
       " 681: 39,\n",
       " 682: 114,\n",
       " 683: 35,\n",
       " 684: 70,\n",
       " 685: 153,\n",
       " 686: 23,\n",
       " 687: 104,\n",
       " 688: 126,\n",
       " 689: 45,\n",
       " 690: 156,\n",
       " 691: 37,\n",
       " 692: 113,\n",
       " 693: 32,\n",
       " 694: 148,\n",
       " 695: 89,\n",
       " 696: 235,\n",
       " 697: 20,\n",
       " 698: 20,\n",
       " 699: 37,\n",
       " 700: 33,\n",
       " 701: 104,\n",
       " 702: 137,\n",
       " 703: 220,\n",
       " 704: 85,\n",
       " 705: 161,\n",
       " 706: 166,\n",
       " 707: 29,\n",
       " 708: 268,\n",
       " 709: 21,\n",
       " 710: 27,\n",
       " 711: 66,\n",
       " 712: 30,\n",
       " 713: 167,\n",
       " 714: 43,\n",
       " 715: 92,\n",
       " 716: 38,\n",
       " 717: 28,\n",
       " 718: 41,\n",
       " 719: 84,\n",
       " 720: 321,\n",
       " 721: 24,\n",
       " 722: 28,\n",
       " 723: 29,\n",
       " 724: 20,\n",
       " 725: 23,\n",
       " 726: 25,\n",
       " 727: 46,\n",
       " 728: 147,\n",
       " 729: 23,\n",
       " 730: 63,\n",
       " 731: 37,\n",
       " 732: 34,\n",
       " 733: 25,\n",
       " 734: 32,\n",
       " 735: 106,\n",
       " 736: 59,\n",
       " 737: 19,\n",
       " 738: 52,\n",
       " 739: 292,\n",
       " 740: 21,\n",
       " 741: 34,\n",
       " 742: 304,\n",
       " 743: 107,\n",
       " 744: 66,\n",
       " 745: 82,\n",
       " 746: 32,\n",
       " 747: 103,\n",
       " 748: 167,\n",
       " 749: 108,\n",
       " 750: 165,\n",
       " 751: 72,\n",
       " 752: 356,\n",
       " 753: 19,\n",
       " 754: 20,\n",
       " 755: 26,\n",
       " 756: 33,\n",
       " 757: 56,\n",
       " 758: 128,\n",
       " 759: 108,\n",
       " 760: 36,\n",
       " 761: 28,\n",
       " 762: 37,\n",
       " 763: 69,\n",
       " 764: 63,\n",
       " 765: 160,\n",
       " 766: 22,\n",
       " 767: 32,\n",
       " 768: 174,\n",
       " 769: 223,\n",
       " 770: 40,\n",
       " 771: 65,\n",
       " 772: 35,\n",
       " 773: 31,\n",
       " 774: 104,\n",
       " 775: 54,\n",
       " 776: 36,\n",
       " 777: 64,\n",
       " 778: 231,\n",
       " 779: 116,\n",
       " 780: 38,\n",
       " 781: 63,\n",
       " 782: 248,\n",
       " 783: 32,\n",
       " 784: 230,\n",
       " 785: 56,\n",
       " 786: 29,\n",
       " 787: 26,\n",
       " 788: 38,\n",
       " 789: 41,\n",
       " 790: 357,\n",
       " 791: 158,\n",
       " 792: 54,\n",
       " 793: 238,\n",
       " 794: 24,\n",
       " 795: 74,\n",
       " 796: 27,\n",
       " 797: 331,\n",
       " 798: 32,\n",
       " 799: 27,\n",
       " 800: 46,\n",
       " 801: 23,\n",
       " 802: 272,\n",
       " 803: 139,\n",
       " 804: 203,\n",
       " 805: 25,\n",
       " 806: 25,\n",
       " 807: 19,\n",
       " 808: 182,\n",
       " 809: 35,\n",
       " 810: 61,\n",
       " 811: 20,\n",
       " 812: 34,\n",
       " 813: 19,\n",
       " 814: 184,\n",
       " 815: 144,\n",
       " 816: 27,\n",
       " 817: 63,\n",
       " 818: 20,\n",
       " 819: 105,\n",
       " 820: 114,\n",
       " 821: 72,\n",
       " 822: 27,\n",
       " 823: 103,\n",
       " 824: 22,\n",
       " 825: 101,\n",
       " 826: 266,\n",
       " 827: 49,\n",
       " 828: 24,\n",
       " 829: 92,\n",
       " 830: 56,\n",
       " 831: 196,\n",
       " 832: 24,\n",
       " 833: 25,\n",
       " 834: 80,\n",
       " 835: 203,\n",
       " 836: 53,\n",
       " 837: 404,\n",
       " 838: 45,\n",
       " 839: 28,\n",
       " 840: 26,\n",
       " 841: 145,\n",
       " 842: 149,\n",
       " 843: 24,\n",
       " 844: 48,\n",
       " 845: 208,\n",
       " 846: 22,\n",
       " 847: 216,\n",
       " 848: 50,\n",
       " 849: 20,\n",
       " 850: 40,\n",
       " 851: 22,\n",
       " 852: 19,\n",
       " 853: 30,\n",
       " 854: 30,\n",
       " 855: 38,\n",
       " 856: 164,\n",
       " 857: 25,\n",
       " 858: 20,\n",
       " 859: 106,\n",
       " 860: 70,\n",
       " 861: 21,\n",
       " 862: 293,\n",
       " 863: 65,\n",
       " 864: 207,\n",
       " 865: 94,\n",
       " 866: 42,\n",
       " 867: 268,\n",
       " 868: 114,\n",
       " 869: 88,\n",
       " 870: 20,\n",
       " 871: 70,\n",
       " 872: 19,\n",
       " 873: 80,\n",
       " 874: 19,\n",
       " 875: 367,\n",
       " 876: 133,\n",
       " 877: 46,\n",
       " 878: 258,\n",
       " 879: 28,\n",
       " 880: 267,\n",
       " 881: 136,\n",
       " 882: 42,\n",
       " 883: 239,\n",
       " 884: 101,\n",
       " 885: 325,\n",
       " 886: 33,\n",
       " 887: 225,\n",
       " 888: 118,\n",
       " 889: 58,\n",
       " 890: 170,\n",
       " 891: 46,\n",
       " 892: 244,\n",
       " 893: 361,\n",
       " 894: 184,\n",
       " 895: 123,\n",
       " 896: 134,\n",
       " 897: 135,\n",
       " 898: 46,\n",
       " 899: 146,\n",
       " 900: 39,\n",
       " 901: 48,\n",
       " 902: 29,\n",
       " 903: 19,\n",
       " 904: 40,\n",
       " 905: 44,\n",
       " 906: 73,\n",
       " 907: 316,\n",
       " 908: 97,\n",
       " 909: 52,\n",
       " 910: 22,\n",
       " 911: 102,\n",
       " 912: 216,\n",
       " 913: 109,\n",
       " 914: 59,\n",
       " 915: 131,\n",
       " 916: 25,\n",
       " 917: 126,\n",
       " 918: 73,\n",
       " 919: 31,\n",
       " 920: 119,\n",
       " 921: 81,\n",
       " 922: 48,\n",
       " 923: 60,\n",
       " 924: 34,\n",
       " 925: 240,\n",
       " 926: 25,\n",
       " 927: 173,\n",
       " 928: 183,\n",
       " 929: 38,\n",
       " 930: 107,\n",
       " 931: 106,\n",
       " 932: 19,\n",
       " 933: 31,\n",
       " 934: 78,\n",
       " 935: 39,\n",
       " 936: 19,\n",
       " 937: 167,\n",
       " 938: 48,\n",
       " 939: 141,\n",
       " 940: 62,\n",
       " 941: 25,\n",
       " 942: 21}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_degree = {user_idx: model_wrapper.adj_norm[user_idx]._nnz() for user_idx in range(model_wrapper.num_users)}\n",
    "user_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_degree = {user_idx: model_wrapper.adj_norm[user_idx]._nnz() for user_idx in range(model_wrapper.num_users)}\n",
    "user_degree_ts = torch.tensor(list(user_degree.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2585, 0.6190, 0.8639, 1.6122, 0.1293, 0.8571, 0.6190, 0.6531, 1.5034,\n",
       "        1.4286, 1.5714, 1.9524, 1.4626, 0.8912, 0.9524, 3.2857, 0.4082, 2.0680,\n",
       "        2.0068, 3.2585, 1.2245, 0.4626, 1.8980, 2.6939, 1.8844, 0.8163, 1.4626,\n",
       "        0.6259, 0.8095, 0.1565, 1.8639, 0.1769, 1.0136, 0.4218, 0.3401, 2.9524,\n",
       "        0.1497, 3.5170, 2.7347, 1.2449, 0.3129, 2.6190, 0.4150, 1.3197, 0.1293,\n",
       "        1.0884, 0.9184, 1.8503, 0.5170, 0.3878, 0.1565, 0.5238, 2.5918, 0.9252,\n",
       "        1.4286, 1.2381, 0.8367, 0.3197, 4.3197, 0.3401, 1.4082, 0.7143, 0.7075,\n",
       "        1.2653, 0.5442, 2.6327, 0.1497, 1.0748, 2.6327, 0.1497, 2.6259, 1.2517,\n",
       "        1.2245, 0.3946, 0.2789, 2.9456, 2.1429, 0.5306, 0.3673, 0.2721, 2.0340,\n",
       "        0.8844, 0.8231, 1.8844, 0.3061, 1.2245, 0.4626, 0.8980, 1.0408, 0.3197,\n",
       "        2.7143, 1.2449, 1.0204, 0.8095, 0.3469, 1.1361, 1.0816, 1.1973, 1.4966,\n",
       "        0.4558, 2.1905, 0.3061, 1.9524, 0.8503, 0.4966, 1.4558, 0.1429, 0.2245,\n",
       "        0.1769, 0.1293, 2.2245, 1.1837, 0.1905, 0.2517, 1.8776, 0.7211, 2.3946,\n",
       "        1.4014, 1.8435, 1.2653, 0.7007, 1.5578, 0.6259, 0.3741, 0.3878, 0.4354,\n",
       "        1.2313, 1.0476, 0.3401, 2.0816, 0.4354, 0.9456, 0.6599, 1.0136, 0.1973,\n",
       "        0.1293, 0.8844, 0.6599, 1.3265, 0.7415, 0.8639, 0.2313, 0.3946, 0.7551,\n",
       "        1.2993, 0.8163, 0.3401, 0.6395, 0.1837, 0.3537, 0.3605, 1.1701, 0.1361,\n",
       "        1.0204, 0.9932, 0.1565, 0.3401, 0.4830, 0.9320, 0.3741, 0.1429, 0.4490,\n",
       "        1.7007, 0.3061, 0.1701, 0.6259, 0.4354, 0.7483, 0.1565, 1.3946, 0.1769,\n",
       "        0.1361, 0.2177, 0.7755, 0.2857, 1.2109, 0.7959, 0.1633, 0.4218, 0.8367,\n",
       "        0.8299, 1.5850, 1.3537, 0.3197, 1.0748, 0.5782, 0.5374, 0.3129, 0.3810,\n",
       "        0.1565, 0.2109, 0.3741, 0.9660, 0.4422, 0.9864, 0.6327, 0.4218, 0.1701,\n",
       "        0.1837, 0.1973, 0.3197, 0.1973, 0.8980, 0.2993, 0.1361, 1.7483, 0.5034,\n",
       "        0.7143, 0.5102, 0.3673, 0.5306, 0.1429, 0.1429, 0.1361, 0.4762, 0.3537,\n",
       "        0.1837, 0.1429, 0.3333, 0.2109, 0.2857, 0.3197, 0.2109, 0.4762, 0.7551,\n",
       "        0.4422, 1.9932, 0.1973, 0.2177, 0.4150, 0.1429, 0.3741, 0.1293, 0.7211,\n",
       "        0.1905, 0.2245, 0.2449, 0.3810, 0.7211, 0.6463, 0.2177, 0.1633, 0.5578,\n",
       "        0.5102, 0.1361, 0.3946, 0.4558, 0.1837, 1.7755, 0.1837, 0.1565, 0.2381,\n",
       "        0.4218, 0.4286, 1.5102, 0.2517, 0.1497, 0.1429, 0.1293, 0.2653, 0.1293,\n",
       "        0.3605, 0.4286, 0.5510, 1.6599, 0.2313, 0.2789, 0.1565, 0.1701, 0.3605,\n",
       "        0.3878, 0.1361, 0.1633, 0.1361, 0.1633, 0.1293, 0.1497, 0.1293, 0.2517,\n",
       "        0.1497, 0.2789, 0.5850, 0.2381, 0.5034, 0.1905, 1.1769, 0.2857, 0.1701,\n",
       "        0.1769, 0.1769, 0.2177, 0.1769, 0.1361, 0.1429, 0.1701, 0.8435, 0.1497,\n",
       "        0.2585, 0.1905, 0.1497, 0.5986, 0.1973, 0.2449, 0.1769, 0.3401, 0.2313,\n",
       "        0.1497, 0.1361, 0.9592, 1.0408, 1.2653, 1.9252, 0.3537, 1.9184, 0.3401,\n",
       "        0.9932, 0.1633, 0.4694, 1.2381, 0.4354, 0.1497, 0.1565, 0.1293, 0.1497,\n",
       "        0.1701, 2.2585, 0.1429, 0.4422, 0.1429, 0.8776, 0.1429, 0.2449, 0.5034,\n",
       "        1.7211, 0.1293, 1.3605, 0.2925, 0.1429, 0.1361, 1.6054, 1.2857, 1.5714,\n",
       "        1.3061, 1.3469, 0.1429, 0.1361, 0.2721, 0.3878, 1.5782, 0.2925, 0.2857,\n",
       "        0.2789, 0.6871, 2.1088, 0.1701, 0.1633, 0.5102, 0.1565, 0.8163, 0.3878,\n",
       "        0.3333, 0.3878, 0.2993, 0.3401, 1.5782, 0.5034, 1.8571, 0.4422, 0.2245,\n",
       "        2.5442, 0.2177, 0.2177, 0.1837, 0.1769, 1.3265, 1.0952, 0.8571, 1.9048,\n",
       "        0.3537, 2.0612, 0.1293, 0.1429, 0.3469, 0.1497, 1.8367, 0.4762, 0.2041,\n",
       "        3.0408, 0.7483, 0.1973, 1.0068, 0.8163, 1.1633, 0.6871, 2.1633, 0.3605,\n",
       "        1.0340, 0.4558, 0.1429, 0.3810, 0.1633, 0.3333, 5.0068, 0.1429, 2.3197,\n",
       "        1.5306, 1.3741, 0.2925, 0.3333, 3.3469, 0.1769, 0.1837, 0.3878, 2.4762,\n",
       "        0.3401, 0.2381, 0.6531, 1.3810, 0.2109, 0.1565, 0.4286, 2.8095, 0.3673,\n",
       "        0.2041, 0.1293, 0.2925, 0.4150, 0.4150, 2.5714, 0.2721, 0.6803, 0.9796,\n",
       "        0.4354, 0.2925, 1.7823, 0.2177, 0.1361, 0.9660, 0.3401, 0.9116, 0.9388,\n",
       "        0.5034, 3.6667, 0.2381, 0.2041, 0.6599, 1.3946, 1.5986, 1.0544, 0.1633,\n",
       "        1.2789, 0.1565, 0.2517, 1.8776, 1.4694, 1.2381, 0.2177, 0.7959, 0.4558,\n",
       "        0.1497, 0.2925, 0.9660, 0.6803, 1.7823, 0.5374, 0.8980, 0.2041, 2.2177,\n",
       "        0.2857, 0.3537, 0.5578, 0.7619, 0.2313, 0.3810, 0.4014, 0.1293, 1.3673,\n",
       "        0.9388, 1.2789, 1.5646, 0.1701, 0.3741, 0.3673, 0.9116, 0.3810, 0.7347,\n",
       "        0.3946, 0.8707, 0.3129, 1.4422, 0.2313, 1.8912, 1.0408, 1.0068, 0.6871,\n",
       "        0.2177, 1.5238, 0.2449, 1.0816, 1.7007, 0.7551, 1.6395, 0.1565, 0.3878,\n",
       "        1.3129, 0.5850, 0.1565, 0.2653, 0.1361, 0.1429, 0.1293, 0.6735, 0.4898,\n",
       "        0.2177, 0.1361, 0.1973, 2.0748, 0.4898, 0.3605, 1.0136, 0.1497, 0.3265,\n",
       "        0.3537, 1.8571, 0.2993, 0.1973, 0.2857, 0.2449, 0.9252, 0.1701, 1.7619,\n",
       "        1.4762, 1.1020, 0.4558, 3.3265, 0.5374, 0.8980, 0.5442, 0.9116, 1.0952,\n",
       "        0.3741, 0.1497, 1.3333, 1.0476, 0.3946, 0.1973, 2.2653, 0.2041, 0.6735,\n",
       "        0.5646, 0.4218, 0.7687, 0.2653, 0.2925, 0.5102, 0.6803, 2.4218, 0.1973,\n",
       "        1.0068, 0.3537, 0.1293, 0.2245, 0.2313, 0.3401, 0.1633, 1.0476, 0.4694,\n",
       "        0.4830, 0.2381, 1.2721, 0.4966, 0.3061, 0.3469, 0.1293, 0.1701, 0.1565,\n",
       "        1.5238, 0.6599, 0.5442, 1.1224, 0.5374, 0.4150, 0.5646, 0.1837, 2.4422,\n",
       "        0.3129, 0.3197, 1.0544, 0.1769, 0.1293, 0.1429, 0.3129, 0.2857, 0.1633,\n",
       "        0.2721, 0.1565, 1.0000, 0.1905, 0.5986, 0.6054, 0.3129, 0.6463, 1.5986,\n",
       "        1.1020, 0.2449, 0.5034, 0.2789, 0.7279, 1.4626, 0.2585, 0.1837, 0.6939,\n",
       "        0.2857, 0.7415, 0.1293, 0.5986, 0.1837, 1.5442, 1.1565, 0.1769, 0.9524,\n",
       "        0.1769, 1.2245, 0.2993, 0.1769, 0.7143, 0.8163, 0.3878, 0.7959, 0.1293,\n",
       "        0.9116, 1.0000, 0.7279, 2.1565, 0.7007, 0.7347, 0.2109, 1.3946, 0.1633,\n",
       "        0.4490, 0.2245, 0.2789, 0.1293, 0.8231, 2.0136, 0.3878, 2.1088, 0.1361,\n",
       "        0.9932, 1.9184, 4.6531, 0.1565, 0.4762, 0.1565, 1.5170, 1.2925, 0.2517,\n",
       "        1.0680, 1.1224, 0.1905, 0.9592, 1.6599, 0.8163, 0.1497, 0.3129, 0.2653,\n",
       "        0.3061, 0.2313, 0.8367, 0.6735, 0.5170, 0.2721, 0.1429, 0.3265, 2.7075,\n",
       "        0.4150, 0.5782, 0.1293, 0.5034, 0.2109, 0.1905, 0.2653, 0.7755, 0.2381,\n",
       "        0.4762, 1.0408, 0.1565, 0.7075, 0.8571, 0.3061, 1.0612, 0.2517, 0.7687,\n",
       "        0.2177, 1.0068, 0.6054, 1.5986, 0.1361, 0.1361, 0.2517, 0.2245, 0.7075,\n",
       "        0.9320, 1.4966, 0.5782, 1.0952, 1.1293, 0.1973, 1.8231, 0.1429, 0.1837,\n",
       "        0.4490, 0.2041, 1.1361, 0.2925, 0.6259, 0.2585, 0.1905, 0.2789, 0.5714,\n",
       "        2.1837, 0.1633, 0.1905, 0.1973, 0.1361, 0.1565, 0.1701, 0.3129, 1.0000,\n",
       "        0.1565, 0.4286, 0.2517, 0.2313, 0.1701, 0.2177, 0.7211, 0.4014, 0.1293,\n",
       "        0.3537, 1.9864, 0.1429, 0.2313, 2.0680, 0.7279, 0.4490, 0.5578, 0.2177,\n",
       "        0.7007, 1.1361, 0.7347, 1.1224, 0.4898, 2.4218, 0.1293, 0.1361, 0.1769,\n",
       "        0.2245, 0.3810, 0.8707, 0.7347, 0.2449, 0.1905, 0.2517, 0.4694, 0.4286,\n",
       "        1.0884, 0.1497, 0.2177, 1.1837, 1.5170, 0.2721, 0.4422, 0.2381, 0.2109,\n",
       "        0.7075, 0.3673, 0.2449, 0.4354, 1.5714, 0.7891, 0.2585, 0.4286, 1.6871,\n",
       "        0.2177, 1.5646, 0.3810, 0.1973, 0.1769, 0.2585, 0.2789, 2.4286, 1.0748,\n",
       "        0.3673, 1.6190, 0.1633, 0.5034, 0.1837, 2.2517, 0.2177, 0.1837, 0.3129,\n",
       "        0.1565, 1.8503, 0.9456, 1.3810, 0.1701, 0.1701, 0.1293, 1.2381, 0.2381,\n",
       "        0.4150, 0.1361, 0.2313, 0.1293, 1.2517, 0.9796, 0.1837, 0.4286, 0.1361,\n",
       "        0.7143, 0.7755, 0.4898, 0.1837, 0.7007, 0.1497, 0.6871, 1.8095, 0.3333,\n",
       "        0.1633, 0.6259, 0.3810, 1.3333, 0.1633, 0.1701, 0.5442, 1.3810, 0.3605,\n",
       "        2.7483, 0.3061, 0.1905, 0.1769, 0.9864, 1.0136, 0.1633, 0.3265, 1.4150,\n",
       "        0.1497, 1.4694, 0.3401, 0.1361, 0.2721, 0.1497, 0.1293, 0.2041, 0.2041,\n",
       "        0.2585, 1.1156, 0.1701, 0.1361, 0.7211, 0.4762, 0.1429, 1.9932, 0.4422,\n",
       "        1.4082, 0.6395, 0.2857, 1.8231, 0.7755, 0.5986, 0.1361, 0.4762, 0.1293,\n",
       "        0.5442, 0.1293, 2.4966, 0.9048, 0.3129, 1.7551, 0.1905, 1.8163, 0.9252,\n",
       "        0.2857, 1.6259, 0.6871, 2.2109, 0.2245, 1.5306, 0.8027, 0.3946, 1.1565,\n",
       "        0.3129, 1.6599, 2.4558, 1.2517, 0.8367, 0.9116, 0.9184, 0.3129, 0.9932,\n",
       "        0.2653, 0.3265, 0.1973, 0.1293, 0.2721, 0.2993, 0.4966, 2.1497, 0.6599,\n",
       "        0.3537, 0.1497, 0.6939, 1.4694, 0.7415, 0.4014, 0.8912, 0.1701, 0.8571,\n",
       "        0.4966, 0.2109, 0.8095, 0.5510, 0.3265, 0.4082, 0.2313, 1.6327, 0.1701,\n",
       "        1.1769, 1.2449, 0.2585, 0.7279, 0.7211, 0.1293, 0.2109, 0.5306, 0.2653,\n",
       "        0.1293, 1.1361, 0.3265, 0.9592, 0.4218, 0.1701, 0.1429])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(1, user_degree_ts / torch.quantile(user_degree_ts.float(), 0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(user_degree.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xiaoyicong\\anaconda3\\envs\\dinghui101\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1910, -0.6757,  0.3772,  ..., -0.2097, -0.5178, -0.1038],\n",
       "        [-0.0419, -0.3186, -0.1524,  ..., -0.4141, -0.2935, -0.3454],\n",
       "        [ 0.2559, -0.6586, -0.0416,  ..., -0.0947, -0.5442, -0.5491],\n",
       "        ...,\n",
       "        [ 0.2413, -0.6668, -0.0095,  ..., -0.0990, -0.5253, -0.5195],\n",
       "        [ 0.2623, -0.6845, -0.0278,  ..., -0.0842, -0.5453, -0.5355],\n",
       "        [-0.0223, -0.6105, -0.1491,  ...,  0.0416,  0.1750, -0.3519]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "user_degree = {user_idx: model_wrapper.adj_norm[user_idx]._nnz() for user_idx in range(model_wrapper.num_users)}\n",
    "user_degree_ts = torch.tensor(list(user_degree.values()))\n",
    "user_degree_ts = user_degree_ts / torch.max(user_degree_ts)\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "\n",
    "# Assume model.user_embedding.weight contains the embeddings of data points\n",
    "user_embedding = model.user_embedding.weight\n",
    "\n",
    "# Convert embeddings to numpy array for KMeans clustering\n",
    "user_embedding_np = user_embedding.cpu().detach().numpy()\n",
    "\n",
    "# Apply KMeans clustering\n",
    "num_clusters = 10  # Set the number of clusters\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "cluster_assignments = kmeans.fit_predict(user_embedding_np)\n",
    "\n",
    "# Move cluster assignments back to torch tensor on GPU\n",
    "cluster_assignments_tensor = torch.from_numpy(cluster_assignments).to(device)\n",
    "\n",
    "# Compute the sum of embeddings for each cluster using matrix operations\n",
    "cluster_sums = torch.zeros(num_clusters, user_embedding.size(1), device=device)\n",
    "cluster_counts = torch.zeros(num_clusters, device=device)\n",
    "\n",
    "# Calculate the sum of embeddings for each cluster using matrix operations\n",
    "for i in range(user_embedding.size(0)):\n",
    "    cluster_id = cluster_assignments_tensor[i]\n",
    "    cluster_sums[cluster_id] += user_embedding[i]\n",
    "    cluster_counts[cluster_id] += 1\n",
    "\n",
    "# Compute the transformed embeddings\n",
    "alphas = user_degree_ts.unsqueeze(1)\n",
    "transformed_embeddings = alphas * user_embedding + (1-alphas)*cluster_sums[cluster_assignments_tensor] / cluster_counts[cluster_assignments_tensor].unsqueeze(1)\n",
    "\n",
    "transformed_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0399, -0.6872,  0.2115,  ..., -0.1991, -0.5630, -0.1116],\n",
       "        [ 0.0414, -0.1972, -0.2142,  ..., -0.5335, -0.0364, -0.5535],\n",
       "        [ 0.2428, -0.5653, -0.1471,  ..., -0.1545, -0.5591, -0.6355],\n",
       "        ...,\n",
       "        [ 0.0527, -0.5441,  0.1013,  ..., -0.2812, -0.3534, -0.3933],\n",
       "        [ 0.3678, -0.8689, -0.2592,  ..., -0.1397, -0.6673, -0.6609],\n",
       "        [ 0.0491, -0.6234, -0.1508,  ...,  0.0828,  0.1856, -0.4175]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]),\n",
       " tensor([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = torch.ones(user_embedding.size(0)).unsqueeze(1)\n",
    "alphas, 1-alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0399, -0.6872,  0.2115,  ..., -0.1991, -0.5630, -0.1116],\n",
       "        [ 0.0414, -0.1972, -0.2142,  ..., -0.5335, -0.0364, -0.5535],\n",
       "        [ 0.2428, -0.5653, -0.1471,  ..., -0.1545, -0.5591, -0.6355],\n",
       "        ...,\n",
       "        [ 0.0527, -0.5441,  0.1013,  ..., -0.2812, -0.3534, -0.3933],\n",
       "        [ 0.3678, -0.8689, -0.2592,  ..., -0.1397, -0.6673, -0.6609],\n",
       "        [ 0.0491, -0.6234, -0.1508,  ...,  0.0828,  0.1856, -0.4175]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_embedding * alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[   0,    0,    0,  ..., 2622, 2623, 2624],\n",
       "                       [ 943,  953, 1026,  ...,  650,  650,  650]]),\n",
       "       values=tensor([0.0151, 0.0094, 0.0099,  ..., 0.0382, 0.0382, 0.0382]),\n",
       "       size=(2625, 2625), nnz=198114, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wrapper.adj_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198114"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_wrapper.adj_norm.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99057"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wrapper.train_df['label'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_wrapper.train_df['user_idx'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2625"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1682 + 943"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_idx</th>\n",
       "      <th>item_idx</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>528</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>377</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>522</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>431</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495280</th>\n",
       "      <td>232</td>\n",
       "      <td>771</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495281</th>\n",
       "      <td>232</td>\n",
       "      <td>1433</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495282</th>\n",
       "      <td>232</td>\n",
       "      <td>1084</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495283</th>\n",
       "      <td>232</td>\n",
       "      <td>1275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495284</th>\n",
       "      <td>232</td>\n",
       "      <td>1563</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>495285 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_idx  item_idx  rating  label\n",
       "0              0         0       3      1\n",
       "1              0       528       4      1\n",
       "2              0       377       4      1\n",
       "3              0       522       3      1\n",
       "4              0       431       5      1\n",
       "...          ...       ...     ...    ...\n",
       "495280       232       771       0      0\n",
       "495281       232      1433       0      0\n",
       "495282       232      1084       0      0\n",
       "495283       232      1275       0      0\n",
       "495284       232      1563       0      0\n",
       "\n",
       "[495285 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wrapper.train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = model_wrapper.train_df[model_wrapper.train_df['label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_idx</th>\n",
       "      <th>item_idx</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>476</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>305</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>627</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1</td>\n",
       "      <td>452</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1</td>\n",
       "      <td>446</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1</td>\n",
       "      <td>491</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_idx  item_idx  rating  label\n",
       "38          1         1       3      1\n",
       "39          1       476       5      1\n",
       "40          1       305       1      1\n",
       "41          1       577       4      1\n",
       "42          1       627       3      1\n",
       "..        ...       ...     ...    ...\n",
       "124         1       172       5      1\n",
       "125         1       136       3      1\n",
       "126         1       452       4      1\n",
       "127         1       446       2      1\n",
       "128         1       491       1      1\n",
       "\n",
       "[91 rows x 4 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"user_idx\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_idx</th>\n",
       "      <th>item_idx</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97496</th>\n",
       "      <td>923</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97866</th>\n",
       "      <td>927</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98372</th>\n",
       "      <td>931</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98585</th>\n",
       "      <td>936</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99020</th>\n",
       "      <td>941</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_idx  item_idx  rating  label\n",
       "38            1         1       3      1\n",
       "721           6         1       4      1\n",
       "857           8         1       4      1\n",
       "1202          9         1       4      1\n",
       "1268         10         1       3      1\n",
       "...         ...       ...     ...    ...\n",
       "97496       923         1       4      1\n",
       "97866       927         1       4      1\n",
       "98372       931         1       4      1\n",
       "98585       936         1       4      1\n",
       "99020       941         1       4      1\n",
       "\n",
       "[288 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"item_idx\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wrapper.adj_norm[1]._nnz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0516, 0.1236, 0.1726, 0.3220, 0.0258, 0.1712, 0.1236, 0.1304, 0.3003,\n",
       "        0.2853, 0.3139, 0.3899, 0.2921, 0.1780, 0.1902, 0.6562, 0.0815, 0.4130,\n",
       "        0.4008, 0.6508, 0.2446, 0.0924, 0.3791, 0.5380, 0.3764, 0.1630, 0.2921,\n",
       "        0.1250, 0.1617, 0.0312, 0.3723, 0.0353, 0.2024, 0.0842, 0.0679, 0.5897,\n",
       "        0.0299, 0.7024, 0.5462, 0.2486, 0.0625, 0.5231, 0.0829, 0.2636, 0.0258,\n",
       "        0.2174, 0.1834, 0.3696, 0.1033, 0.0774, 0.0312, 0.1046, 0.5177, 0.1848,\n",
       "        0.2853, 0.2473, 0.1671, 0.0639, 0.8628, 0.0679, 0.2812, 0.1427, 0.1413,\n",
       "        0.2527, 0.1087, 0.5258, 0.0299, 0.2147, 0.5258, 0.0299, 0.5245, 0.2500,\n",
       "        0.2446, 0.0788, 0.0557, 0.5883, 0.4280, 0.1060, 0.0734, 0.0543, 0.4062,\n",
       "        0.1766, 0.1644, 0.3764, 0.0611, 0.2446, 0.0924, 0.1793, 0.2079, 0.0639,\n",
       "        0.5421, 0.2486, 0.2038, 0.1617, 0.0693, 0.2269, 0.2160, 0.2391, 0.2989,\n",
       "        0.0910, 0.4375, 0.0611, 0.3899, 0.1698, 0.0992, 0.2908, 0.0285, 0.0448,\n",
       "        0.0353, 0.0258, 0.4443, 0.2364, 0.0380, 0.0503, 0.3750, 0.1440, 0.4783,\n",
       "        0.2799, 0.3682, 0.2527, 0.1399, 0.3111, 0.1250, 0.0747, 0.0774, 0.0870,\n",
       "        0.2459, 0.2092, 0.0679, 0.4158, 0.0870, 0.1889, 0.1318, 0.2024, 0.0394,\n",
       "        0.0258, 0.1766, 0.1318, 0.2649, 0.1481, 0.1726, 0.0462, 0.0788, 0.1508,\n",
       "        0.2595, 0.1630, 0.0679, 0.1277, 0.0367, 0.0707, 0.0720, 0.2337, 0.0272,\n",
       "        0.2038, 0.1984, 0.0312, 0.0679, 0.0965, 0.1861, 0.0747, 0.0285, 0.0897,\n",
       "        0.3397, 0.0611, 0.0340, 0.1250, 0.0870, 0.1495, 0.0312, 0.2785, 0.0353,\n",
       "        0.0272, 0.0435, 0.1549, 0.0571, 0.2418, 0.1590, 0.0326, 0.0842, 0.1671,\n",
       "        0.1658, 0.3166, 0.2704, 0.0639, 0.2147, 0.1155, 0.1073, 0.0625, 0.0761,\n",
       "        0.0312, 0.0421, 0.0747, 0.1929, 0.0883, 0.1970, 0.1264, 0.0842, 0.0340,\n",
       "        0.0367, 0.0394, 0.0639, 0.0394, 0.1793, 0.0598, 0.0272, 0.3492, 0.1005,\n",
       "        0.1427, 0.1019, 0.0734, 0.1060, 0.0285, 0.0285, 0.0272, 0.0951, 0.0707,\n",
       "        0.0367, 0.0285, 0.0666, 0.0421, 0.0571, 0.0639, 0.0421, 0.0951, 0.1508,\n",
       "        0.0883, 0.3981, 0.0394, 0.0435, 0.0829, 0.0285, 0.0747, 0.0258, 0.1440,\n",
       "        0.0380, 0.0448, 0.0489, 0.0761, 0.1440, 0.1291, 0.0435, 0.0326, 0.1114,\n",
       "        0.1019, 0.0272, 0.0788, 0.0910, 0.0367, 0.3546, 0.0367, 0.0312, 0.0476,\n",
       "        0.0842, 0.0856, 0.3016, 0.0503, 0.0299, 0.0285, 0.0258, 0.0530, 0.0258,\n",
       "        0.0720, 0.0856, 0.1101, 0.3315, 0.0462, 0.0557, 0.0312, 0.0340, 0.0720,\n",
       "        0.0774, 0.0272, 0.0326, 0.0272, 0.0326, 0.0258, 0.0299, 0.0258, 0.0503,\n",
       "        0.0299, 0.0557, 0.1168, 0.0476, 0.1005, 0.0380, 0.2351, 0.0571, 0.0340,\n",
       "        0.0353, 0.0353, 0.0435, 0.0353, 0.0272, 0.0285, 0.0340, 0.1685, 0.0299,\n",
       "        0.0516, 0.0380, 0.0299, 0.1196, 0.0394, 0.0489, 0.0353, 0.0679, 0.0462,\n",
       "        0.0299, 0.0272, 0.1916, 0.2079, 0.2527, 0.3845, 0.0707, 0.3832, 0.0679,\n",
       "        0.1984, 0.0326, 0.0938, 0.2473, 0.0870, 0.0299, 0.0312, 0.0258, 0.0299,\n",
       "        0.0340, 0.4511, 0.0285, 0.0883, 0.0285, 0.1753, 0.0285, 0.0489, 0.1005,\n",
       "        0.3438, 0.0258, 0.2717, 0.0584, 0.0285, 0.0272, 0.3207, 0.2568, 0.3139,\n",
       "        0.2609, 0.2690, 0.0285, 0.0272, 0.0543, 0.0774, 0.3152, 0.0584, 0.0571,\n",
       "        0.0557, 0.1372, 0.4212, 0.0340, 0.0326, 0.1019, 0.0312, 0.1630, 0.0774,\n",
       "        0.0666, 0.0774, 0.0598, 0.0679, 0.3152, 0.1005, 0.3709, 0.0883, 0.0448,\n",
       "        0.5082, 0.0435, 0.0435, 0.0367, 0.0353, 0.2649, 0.2188, 0.1712, 0.3804,\n",
       "        0.0707, 0.4117, 0.0258, 0.0285, 0.0693, 0.0299, 0.3668, 0.0951, 0.0408,\n",
       "        0.6073, 0.1495, 0.0394, 0.2011, 0.1630, 0.2323, 0.1372, 0.4321, 0.0720,\n",
       "        0.2065, 0.0910, 0.0285, 0.0761, 0.0326, 0.0666, 1.0000, 0.0285, 0.4633,\n",
       "        0.3057, 0.2745, 0.0584, 0.0666, 0.6685, 0.0353, 0.0367, 0.0774, 0.4946,\n",
       "        0.0679, 0.0476, 0.1304, 0.2758, 0.0421, 0.0312, 0.0856, 0.5611, 0.0734,\n",
       "        0.0408, 0.0258, 0.0584, 0.0829, 0.0829, 0.5136, 0.0543, 0.1359, 0.1957,\n",
       "        0.0870, 0.0584, 0.3560, 0.0435, 0.0272, 0.1929, 0.0679, 0.1821, 0.1875,\n",
       "        0.1005, 0.7323, 0.0476, 0.0408, 0.1318, 0.2785, 0.3193, 0.2106, 0.0326,\n",
       "        0.2554, 0.0312, 0.0503, 0.3750, 0.2935, 0.2473, 0.0435, 0.1590, 0.0910,\n",
       "        0.0299, 0.0584, 0.1929, 0.1359, 0.3560, 0.1073, 0.1793, 0.0408, 0.4429,\n",
       "        0.0571, 0.0707, 0.1114, 0.1522, 0.0462, 0.0761, 0.0802, 0.0258, 0.2731,\n",
       "        0.1875, 0.2554, 0.3125, 0.0340, 0.0747, 0.0734, 0.1821, 0.0761, 0.1467,\n",
       "        0.0788, 0.1739, 0.0625, 0.2880, 0.0462, 0.3777, 0.2079, 0.2011, 0.1372,\n",
       "        0.0435, 0.3043, 0.0489, 0.2160, 0.3397, 0.1508, 0.3274, 0.0312, 0.0774,\n",
       "        0.2622, 0.1168, 0.0312, 0.0530, 0.0272, 0.0285, 0.0258, 0.1345, 0.0978,\n",
       "        0.0435, 0.0272, 0.0394, 0.4144, 0.0978, 0.0720, 0.2024, 0.0299, 0.0652,\n",
       "        0.0707, 0.3709, 0.0598, 0.0394, 0.0571, 0.0489, 0.1848, 0.0340, 0.3519,\n",
       "        0.2948, 0.2201, 0.0910, 0.6644, 0.1073, 0.1793, 0.1087, 0.1821, 0.2188,\n",
       "        0.0747, 0.0299, 0.2663, 0.2092, 0.0788, 0.0394, 0.4524, 0.0408, 0.1345,\n",
       "        0.1128, 0.0842, 0.1535, 0.0530, 0.0584, 0.1019, 0.1359, 0.4837, 0.0394,\n",
       "        0.2011, 0.0707, 0.0258, 0.0448, 0.0462, 0.0679, 0.0326, 0.2092, 0.0938,\n",
       "        0.0965, 0.0476, 0.2541, 0.0992, 0.0611, 0.0693, 0.0258, 0.0340, 0.0312,\n",
       "        0.3043, 0.1318, 0.1087, 0.2242, 0.1073, 0.0829, 0.1128, 0.0367, 0.4878,\n",
       "        0.0625, 0.0639, 0.2106, 0.0353, 0.0258, 0.0285, 0.0625, 0.0571, 0.0326,\n",
       "        0.0543, 0.0312, 0.1997, 0.0380, 0.1196, 0.1209, 0.0625, 0.1291, 0.3193,\n",
       "        0.2201, 0.0489, 0.1005, 0.0557, 0.1454, 0.2921, 0.0516, 0.0367, 0.1386,\n",
       "        0.0571, 0.1481, 0.0258, 0.1196, 0.0367, 0.3084, 0.2310, 0.0353, 0.1902,\n",
       "        0.0353, 0.2446, 0.0598, 0.0353, 0.1427, 0.1630, 0.0774, 0.1590, 0.0258,\n",
       "        0.1821, 0.1997, 0.1454, 0.4307, 0.1399, 0.1467, 0.0421, 0.2785, 0.0326,\n",
       "        0.0897, 0.0448, 0.0557, 0.0258, 0.1644, 0.4022, 0.0774, 0.4212, 0.0272,\n",
       "        0.1984, 0.3832, 0.9293, 0.0312, 0.0951, 0.0312, 0.3030, 0.2582, 0.0503,\n",
       "        0.2133, 0.2242, 0.0380, 0.1916, 0.3315, 0.1630, 0.0299, 0.0625, 0.0530,\n",
       "        0.0611, 0.0462, 0.1671, 0.1345, 0.1033, 0.0543, 0.0285, 0.0652, 0.5408,\n",
       "        0.0829, 0.1155, 0.0258, 0.1005, 0.0421, 0.0380, 0.0530, 0.1549, 0.0476,\n",
       "        0.0951, 0.2079, 0.0312, 0.1413, 0.1712, 0.0611, 0.2120, 0.0503, 0.1535,\n",
       "        0.0435, 0.2011, 0.1209, 0.3193, 0.0272, 0.0272, 0.0503, 0.0448, 0.1413,\n",
       "        0.1861, 0.2989, 0.1155, 0.2188, 0.2255, 0.0394, 0.3641, 0.0285, 0.0367,\n",
       "        0.0897, 0.0408, 0.2269, 0.0584, 0.1250, 0.0516, 0.0380, 0.0557, 0.1141,\n",
       "        0.4361, 0.0326, 0.0380, 0.0394, 0.0272, 0.0312, 0.0340, 0.0625, 0.1997,\n",
       "        0.0312, 0.0856, 0.0503, 0.0462, 0.0340, 0.0435, 0.1440, 0.0802, 0.0258,\n",
       "        0.0707, 0.3967, 0.0285, 0.0462, 0.4130, 0.1454, 0.0897, 0.1114, 0.0435,\n",
       "        0.1399, 0.2269, 0.1467, 0.2242, 0.0978, 0.4837, 0.0258, 0.0272, 0.0353,\n",
       "        0.0448, 0.0761, 0.1739, 0.1467, 0.0489, 0.0380, 0.0503, 0.0938, 0.0856,\n",
       "        0.2174, 0.0299, 0.0435, 0.2364, 0.3030, 0.0543, 0.0883, 0.0476, 0.0421,\n",
       "        0.1413, 0.0734, 0.0489, 0.0870, 0.3139, 0.1576, 0.0516, 0.0856, 0.3370,\n",
       "        0.0435, 0.3125, 0.0761, 0.0394, 0.0353, 0.0516, 0.0557, 0.4851, 0.2147,\n",
       "        0.0734, 0.3234, 0.0326, 0.1005, 0.0367, 0.4497, 0.0435, 0.0367, 0.0625,\n",
       "        0.0312, 0.3696, 0.1889, 0.2758, 0.0340, 0.0340, 0.0258, 0.2473, 0.0476,\n",
       "        0.0829, 0.0272, 0.0462, 0.0258, 0.2500, 0.1957, 0.0367, 0.0856, 0.0272,\n",
       "        0.1427, 0.1549, 0.0978, 0.0367, 0.1399, 0.0299, 0.1372, 0.3614, 0.0666,\n",
       "        0.0326, 0.1250, 0.0761, 0.2663, 0.0326, 0.0340, 0.1087, 0.2758, 0.0720,\n",
       "        0.5489, 0.0611, 0.0380, 0.0353, 0.1970, 0.2024, 0.0326, 0.0652, 0.2826,\n",
       "        0.0299, 0.2935, 0.0679, 0.0272, 0.0543, 0.0299, 0.0258, 0.0408, 0.0408,\n",
       "        0.0516, 0.2228, 0.0340, 0.0272, 0.1440, 0.0951, 0.0285, 0.3981, 0.0883,\n",
       "        0.2812, 0.1277, 0.0571, 0.3641, 0.1549, 0.1196, 0.0272, 0.0951, 0.0258,\n",
       "        0.1087, 0.0258, 0.4986, 0.1807, 0.0625, 0.3505, 0.0380, 0.3628, 0.1848,\n",
       "        0.0571, 0.3247, 0.1372, 0.4416, 0.0448, 0.3057, 0.1603, 0.0788, 0.2310,\n",
       "        0.0625, 0.3315, 0.4905, 0.2500, 0.1671, 0.1821, 0.1834, 0.0625, 0.1984,\n",
       "        0.0530, 0.0652, 0.0394, 0.0258, 0.0543, 0.0598, 0.0992, 0.4293, 0.1318,\n",
       "        0.0707, 0.0299, 0.1386, 0.2935, 0.1481, 0.0802, 0.1780, 0.0340, 0.1712,\n",
       "        0.0992, 0.0421, 0.1617, 0.1101, 0.0652, 0.0815, 0.0462, 0.3261, 0.0340,\n",
       "        0.2351, 0.2486, 0.0516, 0.1454, 0.1440, 0.0258, 0.0421, 0.1060, 0.0530,\n",
       "        0.0258, 0.2269, 0.0652, 0.1916, 0.0842, 0.0340, 0.0285])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_degree_ts = torch.tensor(list(user_degree.values()))\n",
    "user_degree_ts / torch.max(user_degree_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1855931757113756e+16"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.1391e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6028e-08, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.7565e-26, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9375e-29, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0262e-09,\n",
       "        0.0000e+00, 5.1091e-11, 0.0000e+00, 1.1851e-26, 1.9287e-21, 0.0000e+00,\n",
       "        2.7895e-09, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0531e-19, 0.0000e+00,\n",
       "        3.2213e-26, 0.0000e+00, 5.6028e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        9.8542e-33, 1.7588e-24, 1.0262e-09, 3.6251e-33, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8740e-20, 0.0000e+00, 1.9287e-21,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8049e-34, 0.0000e+00,\n",
       "        2.7895e-09, 0.0000e+00, 0.0000e+00, 2.7895e-09, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 6.4702e-25, 1.5629e-17, 0.0000e+00, 0.0000e+00, 1.3336e-33,\n",
       "        3.5326e-23, 4.2484e-17, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        2.8625e-19, 0.0000e+00, 2.9375e-29, 0.0000e+00, 0.0000e+00, 3.8740e-20,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0955e-22, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.9849e-29, 0.0000e+00, 2.8625e-19,\n",
       "        0.0000e+00, 0.0000e+00, 1.9793e-31, 0.0000e+00, 7.5826e-09, 4.6589e-14,\n",
       "        5.1091e-11, 5.6028e-08, 0.0000e+00, 0.0000e+00, 6.9144e-12, 8.5330e-16,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2996e-23, 1.7588e-24, 1.6038e-27,\n",
       "        0.0000e+00, 0.0000e+00, 1.9287e-21, 0.0000e+00, 1.6038e-27, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 2.5437e-12, 5.6028e-08, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7139e-14, 6.4702e-25, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.9287e-21, 0.0000e+00, 1.8795e-11, 2.6103e-22,\n",
       "        9.6027e-23, 0.0000e+00, 2.0612e-08, 0.0000e+00, 0.0000e+00, 1.0262e-09,\n",
       "        1.9287e-21, 1.4625e-30, 0.0000e+00, 1.2996e-23, 7.5826e-09, 2.1705e-28,\n",
       "        0.0000e+00, 2.8625e-19, 1.3888e-10, 0.0000e+00, 1.6038e-27, 0.0000e+00,\n",
       "        1.0262e-09, 0.0000e+00, 5.1091e-11, 2.0612e-08, 1.2664e-13, 0.0000e+00,\n",
       "        5.7495e-18, 0.0000e+00, 0.0000e+00, 3.7751e-10, 1.1851e-26, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8740e-20, 0.0000e+00, 1.2161e-36,\n",
       "        4.9061e-34, 1.0531e-19, 4.7809e-24, 1.0262e-09, 3.4425e-13, 1.2996e-23,\n",
       "        0.0000e+00, 5.9001e-28, 0.0000e+00, 0.0000e+00, 1.1851e-26, 1.3888e-10,\n",
       "        1.8795e-11, 2.5437e-12, 3.8740e-20, 2.5437e-12, 0.0000e+00, 7.7811e-19,\n",
       "        2.0612e-08, 0.0000e+00, 7.2813e-32, 0.0000e+00, 2.6786e-32, 3.5326e-23,\n",
       "        1.3336e-33, 7.5826e-09, 7.5826e-09, 2.0612e-08, 3.9754e-30, 2.6103e-22,\n",
       "        1.8795e-11, 7.5826e-09, 5.2429e-21, 3.4425e-13, 5.7495e-18, 3.8740e-20,\n",
       "        3.4425e-13, 3.9754e-30, 0.0000e+00, 5.9001e-28, 0.0000e+00, 2.5437e-12,\n",
       "        1.2664e-13, 3.2213e-26, 7.5826e-09, 1.2996e-23, 5.6028e-08, 0.0000e+00,\n",
       "        6.9144e-12, 4.6589e-14, 2.3195e-15, 4.7809e-24, 0.0000e+00, 0.0000e+00,\n",
       "        1.2664e-13, 3.7751e-10, 2.4426e-35, 2.6786e-32, 2.0612e-08, 6.4702e-25,\n",
       "        7.9849e-29, 1.8795e-11, 0.0000e+00, 1.8795e-11, 1.0262e-09, 6.3051e-15,\n",
       "        1.1851e-26, 4.3596e-27, 0.0000e+00, 8.5330e-16, 2.7895e-09, 7.5826e-09,\n",
       "        5.6028e-08, 1.1548e-16, 5.6028e-08, 9.6027e-23, 4.3596e-27, 6.6397e-35,\n",
       "        0.0000e+00, 1.7139e-14, 1.5629e-17, 1.0262e-09, 1.3888e-10, 9.6027e-23,\n",
       "        1.7588e-24, 2.0612e-08, 3.7751e-10, 2.0612e-08, 3.7751e-10, 5.6028e-08,\n",
       "        2.7895e-09, 5.6028e-08, 8.5330e-16, 2.7895e-09, 1.5629e-17, 4.4738e-37,\n",
       "        6.3051e-15, 7.2813e-32, 6.9144e-12, 0.0000e+00, 5.7495e-18, 1.3888e-10,\n",
       "        5.1091e-11, 5.1091e-11, 1.2664e-13, 5.1091e-11, 2.0612e-08, 7.5826e-09,\n",
       "        1.3888e-10, 0.0000e+00, 2.7895e-09, 3.1391e-16, 6.9144e-12, 2.7895e-09,\n",
       "        6.0546e-38, 2.5437e-12, 2.3195e-15, 5.1091e-11, 1.9287e-21, 1.7139e-14,\n",
       "        2.7895e-09, 2.0612e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        2.6103e-22, 0.0000e+00, 1.9287e-21, 0.0000e+00, 3.7751e-10, 1.0806e-29,\n",
       "        0.0000e+00, 1.6038e-27, 2.7895e-09, 1.0262e-09, 5.6028e-08, 2.7895e-09,\n",
       "        1.3888e-10, 0.0000e+00, 7.5826e-09, 5.9001e-28, 7.5826e-09, 0.0000e+00,\n",
       "        7.5826e-09, 2.3195e-15, 7.2813e-32, 0.0000e+00, 5.6028e-08, 0.0000e+00,\n",
       "        2.1151e-18, 7.5826e-09, 2.0612e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 7.5826e-09, 2.0612e-08, 4.2484e-17, 1.7588e-24,\n",
       "        0.0000e+00, 2.1151e-18, 5.7495e-18, 1.5629e-17, 0.0000e+00, 0.0000e+00,\n",
       "        1.3888e-10, 3.7751e-10, 2.6786e-32, 1.0262e-09, 0.0000e+00, 1.7588e-24,\n",
       "        5.2429e-21, 1.7588e-24, 7.7811e-19, 1.9287e-21, 0.0000e+00, 7.2813e-32,\n",
       "        0.0000e+00, 5.9001e-28, 4.6589e-14, 0.0000e+00, 1.2664e-13, 1.2664e-13,\n",
       "        1.8795e-11, 5.1091e-11, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        2.6103e-22, 0.0000e+00, 5.6028e-08, 7.5826e-09, 7.0955e-22, 2.7895e-09,\n",
       "        0.0000e+00, 3.9754e-30, 9.3576e-13, 0.0000e+00, 0.0000e+00, 2.5437e-12,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.6027e-23,\n",
       "        0.0000e+00, 7.9849e-29, 7.5826e-09, 4.7809e-24, 3.7751e-10, 5.2429e-21,\n",
       "        0.0000e+00, 7.5826e-09, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1151e-18,\n",
       "        5.2429e-21, 0.0000e+00, 5.1091e-11, 1.8795e-11, 1.7588e-24, 0.0000e+00,\n",
       "        1.9287e-21, 6.3051e-15, 0.0000e+00, 0.0000e+00, 3.4425e-13, 1.0262e-09,\n",
       "        4.3596e-27, 0.0000e+00, 3.5326e-23, 9.3576e-13, 5.6028e-08, 2.1151e-18,\n",
       "        3.2213e-26, 3.2213e-26, 0.0000e+00, 4.2484e-17, 0.0000e+00, 0.0000e+00,\n",
       "        1.6038e-27, 2.1151e-18, 0.0000e+00, 1.2664e-13, 2.0612e-08, 0.0000e+00,\n",
       "        1.9287e-21, 0.0000e+00, 0.0000e+00, 7.2813e-32, 0.0000e+00, 6.3051e-15,\n",
       "        9.3576e-13, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7751e-10,\n",
       "        0.0000e+00, 1.0262e-09, 8.5330e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        1.2664e-13, 0.0000e+00, 7.9849e-29, 2.7895e-09, 2.1151e-18, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 4.9061e-34, 0.0000e+00, 9.3576e-13, 0.0000e+00,\n",
       "        5.7495e-18, 2.6103e-22, 2.4426e-35, 0.0000e+00, 1.7139e-14, 4.7809e-24,\n",
       "        2.3803e-25, 5.6028e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        1.3888e-10, 1.2996e-23, 3.5326e-23, 0.0000e+00, 4.7809e-24, 0.0000e+00,\n",
       "        6.4702e-25, 0.0000e+00, 1.0531e-19, 0.0000e+00, 1.7139e-14, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2664e-13, 0.0000e+00, 2.3195e-15,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0262e-09, 1.7588e-24,\n",
       "        0.0000e+00, 4.4738e-37, 1.0262e-09, 1.1548e-16, 2.0612e-08, 7.5826e-09,\n",
       "        5.6028e-08, 0.0000e+00, 5.3802e-31, 1.2664e-13, 2.0612e-08, 2.5437e-12,\n",
       "        0.0000e+00, 5.3802e-31, 9.6027e-23, 0.0000e+00, 2.7895e-09, 1.4252e-20,\n",
       "        2.6103e-22, 0.0000e+00, 7.7811e-19, 2.5437e-12, 5.7495e-18, 2.3195e-15,\n",
       "        0.0000e+00, 1.3888e-10, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.9849e-29,\n",
       "        0.0000e+00, 4.9061e-34, 0.0000e+00, 1.8049e-34, 0.0000e+00, 0.0000e+00,\n",
       "        1.2996e-23, 2.7895e-09, 0.0000e+00, 0.0000e+00, 6.4702e-25, 2.5437e-12,\n",
       "        0.0000e+00, 9.3576e-13, 0.0000e+00, 8.9858e-36, 1.1851e-26, 0.0000e+00,\n",
       "        1.1548e-16, 2.1151e-18, 2.6786e-32, 0.0000e+00, 0.0000e+00, 2.5437e-12,\n",
       "        0.0000e+00, 2.6103e-22, 5.6028e-08, 4.6589e-14, 1.7139e-14, 1.9287e-21,\n",
       "        3.7751e-10, 0.0000e+00, 1.0806e-29, 1.4625e-30, 6.3051e-15, 0.0000e+00,\n",
       "        1.9793e-31, 2.8625e-19, 7.0955e-22, 5.6028e-08, 1.3888e-10, 1.0262e-09,\n",
       "        0.0000e+00, 0.0000e+00, 1.8049e-34, 0.0000e+00, 4.9061e-34, 3.2213e-26,\n",
       "        8.9858e-36, 1.8795e-11, 0.0000e+00, 1.0531e-19, 3.8740e-20, 0.0000e+00,\n",
       "        5.1091e-11, 5.6028e-08, 7.5826e-09, 1.0531e-19, 5.7495e-18, 3.7751e-10,\n",
       "        4.2484e-17, 1.0262e-09, 0.0000e+00, 6.9144e-12, 6.0546e-38, 0.0000e+00,\n",
       "        1.0531e-19, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3195e-15, 7.2813e-32,\n",
       "        1.5629e-17, 0.0000e+00, 0.0000e+00, 3.1391e-16, 1.8795e-11, 0.0000e+00,\n",
       "        5.7495e-18, 0.0000e+00, 5.6028e-08, 6.0546e-38, 1.8795e-11, 0.0000e+00,\n",
       "        0.0000e+00, 5.1091e-11, 0.0000e+00, 5.1091e-11, 0.0000e+00, 7.7811e-19,\n",
       "        5.1091e-11, 0.0000e+00, 0.0000e+00, 1.7588e-24, 0.0000e+00, 5.6028e-08,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        3.4425e-13, 0.0000e+00, 3.7751e-10, 2.1705e-28, 4.6589e-14, 1.5629e-17,\n",
       "        5.6028e-08, 0.0000e+00, 0.0000e+00, 1.7588e-24, 0.0000e+00, 2.0612e-08,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0262e-09, 3.9754e-30, 1.0262e-09,\n",
       "        0.0000e+00, 0.0000e+00, 8.5330e-16, 0.0000e+00, 0.0000e+00, 6.9144e-12,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7895e-09, 1.0531e-19, 1.1548e-16,\n",
       "        2.8625e-19, 1.7139e-14, 0.0000e+00, 0.0000e+00, 9.8542e-33, 4.2484e-17,\n",
       "        7.5826e-09, 1.4252e-20, 0.0000e+00, 3.2213e-26, 1.2161e-36, 5.6028e-08,\n",
       "        7.2813e-32, 3.4425e-13, 6.9144e-12, 1.1548e-16, 0.0000e+00, 6.3051e-15,\n",
       "        3.9754e-30, 0.0000e+00, 1.0262e-09, 0.0000e+00, 0.0000e+00, 2.8625e-19,\n",
       "        0.0000e+00, 8.5330e-16, 0.0000e+00, 1.2664e-13, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 2.0612e-08, 2.0612e-08, 8.5330e-16, 4.6589e-14, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.2161e-36, 0.0000e+00, 0.0000e+00, 2.5437e-12,\n",
       "        0.0000e+00, 7.5826e-09, 1.8795e-11, 2.1705e-28, 9.3576e-13, 0.0000e+00,\n",
       "        2.1151e-18, 0.0000e+00, 3.1391e-16, 6.9144e-12, 1.5629e-17, 3.3057e-36,\n",
       "        0.0000e+00, 3.7751e-10, 6.9144e-12, 2.5437e-12, 2.0612e-08, 1.0262e-09,\n",
       "        1.3888e-10, 1.0531e-19, 0.0000e+00, 1.0262e-09, 4.3596e-27, 8.5330e-16,\n",
       "        1.7139e-14, 1.3888e-10, 1.2664e-13, 0.0000e+00, 2.3803e-25, 5.6028e-08,\n",
       "        2.6103e-22, 0.0000e+00, 7.5826e-09, 1.7139e-14, 0.0000e+00, 0.0000e+00,\n",
       "        2.1705e-28, 2.4426e-35, 1.2664e-13, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 5.3802e-31, 0.0000e+00, 5.6028e-08, 2.0612e-08, 5.1091e-11,\n",
       "        4.6589e-14, 4.7809e-24, 0.0000e+00, 0.0000e+00, 2.3195e-15, 6.9144e-12,\n",
       "        8.5330e-16, 1.0806e-29, 4.3596e-27, 0.0000e+00, 2.7895e-09, 1.2664e-13,\n",
       "        0.0000e+00, 0.0000e+00, 4.2484e-17, 5.9001e-28, 6.3051e-15, 3.4425e-13,\n",
       "        0.0000e+00, 3.5326e-23, 2.3195e-15, 1.6038e-27, 0.0000e+00, 0.0000e+00,\n",
       "        3.1391e-16, 4.3596e-27, 0.0000e+00, 1.2664e-13, 0.0000e+00, 4.7809e-24,\n",
       "        2.5437e-12, 5.1091e-11, 3.1391e-16, 1.5629e-17, 0.0000e+00, 0.0000e+00,\n",
       "        3.5326e-23, 0.0000e+00, 3.7751e-10, 7.2813e-32, 1.8795e-11, 0.0000e+00,\n",
       "        1.2664e-13, 1.8795e-11, 1.0531e-19, 1.0262e-09, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.3888e-10, 1.3888e-10, 5.6028e-08, 0.0000e+00, 6.3051e-15,\n",
       "        3.2213e-26, 2.0612e-08, 1.7139e-14, 5.6028e-08, 0.0000e+00, 0.0000e+00,\n",
       "        1.8795e-11, 4.3596e-27, 2.0612e-08, 0.0000e+00, 0.0000e+00, 5.3802e-31,\n",
       "        1.8795e-11, 0.0000e+00, 2.7895e-09, 0.0000e+00, 0.0000e+00, 5.2429e-21,\n",
       "        3.7751e-10, 0.0000e+00, 4.7809e-24, 0.0000e+00, 3.7751e-10, 1.3888e-10,\n",
       "        1.8049e-34, 0.0000e+00, 9.6027e-23, 0.0000e+00, 2.8625e-19, 6.9144e-12,\n",
       "        5.1091e-11, 0.0000e+00, 0.0000e+00, 3.7751e-10, 1.4252e-20, 0.0000e+00,\n",
       "        2.7895e-09, 0.0000e+00, 1.9287e-21, 2.0612e-08, 4.2484e-17, 2.7895e-09,\n",
       "        5.6028e-08, 9.3576e-13, 9.3576e-13, 3.1391e-16, 0.0000e+00, 1.3888e-10,\n",
       "        2.0612e-08, 0.0000e+00, 3.9754e-30, 7.5826e-09, 0.0000e+00, 5.9001e-28,\n",
       "        0.0000e+00, 0.0000e+00, 5.7495e-18, 0.0000e+00, 0.0000e+00, 6.0546e-38,\n",
       "        2.0612e-08, 3.9754e-30, 5.6028e-08, 1.8049e-34, 5.6028e-08, 0.0000e+00,\n",
       "        0.0000e+00, 1.0531e-19, 0.0000e+00, 6.9144e-12, 0.0000e+00, 0.0000e+00,\n",
       "        5.7495e-18, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6589e-14, 0.0000e+00,\n",
       "        0.0000e+00, 6.4702e-25, 0.0000e+00, 1.0531e-19, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0531e-19, 0.0000e+00,\n",
       "        1.1548e-16, 1.4252e-20, 2.5437e-12, 5.6028e-08, 4.2484e-17, 7.7811e-19,\n",
       "        1.9793e-31, 0.0000e+00, 0.0000e+00, 2.6103e-22, 2.7895e-09, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 2.3803e-25, 0.0000e+00, 1.3888e-10, 0.0000e+00,\n",
       "        1.9793e-31, 3.4425e-13, 0.0000e+00, 6.6397e-35, 1.4252e-20, 8.7565e-26,\n",
       "        1.7139e-14, 0.0000e+00, 1.3888e-10, 0.0000e+00, 0.0000e+00, 3.1391e-16,\n",
       "        0.0000e+00, 0.0000e+00, 5.6028e-08, 3.4425e-13, 1.3336e-33, 1.1548e-16,\n",
       "        5.6028e-08, 0.0000e+00, 1.4252e-20, 0.0000e+00, 1.1851e-26, 1.3888e-10,\n",
       "        7.5826e-09])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/(1 + torch.exp(user_degree_ts)/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinghui101",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
